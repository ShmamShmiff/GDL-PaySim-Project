{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# 0.1%\n",
    "#accounts_df = pd.read_csv(\"../datasets/p_0_1_percent/PS_20230428161042_1211346587/PS_20230428161042_1211346587_account_attributes.csv\")\n",
    "#transactions_df = pd.read_csv(\"../datasets/p_0_1_percent/PS_20230428161042_1211346587/PS_20230428161042_1211346587_rawLog.csv\")\n",
    "\n",
    "# 1%\n",
    "#accounts_df = pd.read_csv(\"../datasets/p_1_percent/PS_20230504121043_87775/PS_20230504121043_87775_account_attributes.csv\")\n",
    "#transactions_df = pd.read_csv(\"../datasets/p_1_percent/PS_20230504121043_87775/PS_20230504121043_87775_rawLog.csv\")\n",
    "\n",
    "# 5%\n",
    "accounts_df = pd.read_csv(\"../datasets/p_5_percent/PS_20230504134819_26105/PS_20230504134819_26105_account_attributes.csv\")\n",
    "transactions_df = pd.read_csv(\"../datasets/p_5_percent/PS_20230504134819_26105/PS_20230504134819_26105_rawLog.csv\")\n",
    "\n",
    "# 10%\n",
    "#accounts_df = pd.read_csv(\"\")\n",
    "#transactions_df = pd.read_csv(\"\")\n",
    "\n",
    "# 20%\n",
    "#accounts_df = pd.read_csv(\"\")\n",
    "#transactions_df = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>action</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <th>newBalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>isUnauthorizedOverdraft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>94.57</td>\n",
       "      <td>C5393210639</td>\n",
       "      <td>94.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC7736975753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>94.57</td>\n",
       "      <td>CC7736975753</td>\n",
       "      <td>94.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M2927363590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>84.47</td>\n",
       "      <td>C2070951585</td>\n",
       "      <td>84.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC3218672791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>84.47</td>\n",
       "      <td>CC3218672791</td>\n",
       "      <td>84.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M3968125771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>91.27</td>\n",
       "      <td>C3284385768</td>\n",
       "      <td>91.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC3328636106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step    action  amount      nameOrig  oldBalanceOrig  newBalanceOrig  \\\n",
       "0     0  TRANSFER   94.57   C5393210639           94.57             0.0   \n",
       "1     0  CASH_OUT   94.57  CC7736975753           94.57             0.0   \n",
       "2     0  TRANSFER   84.47   C2070951585           84.47             0.0   \n",
       "3     0  CASH_OUT   84.47  CC3218672791           84.47             0.0   \n",
       "4     0  TRANSFER   91.27   C3284385768           91.27             0.0   \n",
       "\n",
       "       nameDest  oldBalanceDest  newBalanceDest  isFraud  isFlaggedFraud  \\\n",
       "0  CC7736975753             0.0           94.57        1               0   \n",
       "1   M2927363590             0.0            0.00        1               0   \n",
       "2  CC3218672791             0.0           84.47        1               0   \n",
       "3   M3968125771             0.0            0.00        1               0   \n",
       "4  CC3328636106             0.0           91.27        1               0   \n",
       "\n",
       "   isUnauthorizedOverdraft  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df = accounts_df\n",
    "edges_df = transactions_df\n",
    "\n",
    "\n",
    "nodes_df.head()\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <th>newBalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>isUnauthorizedOverdraft</th>\n",
       "      <th>action_CASH_IN</th>\n",
       "      <th>action_CASH_OUT</th>\n",
       "      <th>action_DEBIT</th>\n",
       "      <th>action_PAYMENT</th>\n",
       "      <th>action_TRANSFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>94.57</td>\n",
       "      <td>C5393210639</td>\n",
       "      <td>94.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC7736975753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>94.57</td>\n",
       "      <td>CC7736975753</td>\n",
       "      <td>94.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M2927363590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>84.47</td>\n",
       "      <td>C2070951585</td>\n",
       "      <td>84.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC3218672791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>84.47</td>\n",
       "      <td>CC3218672791</td>\n",
       "      <td>84.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M3968125771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>91.27</td>\n",
       "      <td>C3284385768</td>\n",
       "      <td>91.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC3328636106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step  amount      nameOrig  oldBalanceOrig  newBalanceOrig      nameDest  \\\n",
       "0     0   94.57   C5393210639           94.57             0.0  CC7736975753   \n",
       "1     0   94.57  CC7736975753           94.57             0.0   M2927363590   \n",
       "2     0   84.47   C2070951585           84.47             0.0  CC3218672791   \n",
       "3     0   84.47  CC3218672791           84.47             0.0   M3968125771   \n",
       "4     0   91.27   C3284385768           91.27             0.0  CC3328636106   \n",
       "\n",
       "   oldBalanceDest  newBalanceDest  isFraud  isFlaggedFraud  \\\n",
       "0             0.0           94.57        1               0   \n",
       "1             0.0            0.00        1               0   \n",
       "2             0.0           84.47        1               0   \n",
       "3             0.0            0.00        1               0   \n",
       "4             0.0           91.27        1               0   \n",
       "\n",
       "   isUnauthorizedOverdraft  action_CASH_IN  action_CASH_OUT  action_DEBIT  \\\n",
       "0                        0               0                0             0   \n",
       "1                        0               0                1             0   \n",
       "2                        0               0                0             0   \n",
       "3                        0               0                1             0   \n",
       "4                        0               0                0             0   \n",
       "\n",
       "   action_PAYMENT  action_TRANSFER  \n",
       "0               0                1  \n",
       "1               0                0  \n",
       "2               0                1  \n",
       "3               0                0  \n",
       "4               0                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummies for the 'action' column\n",
    "dummies = pd.get_dummies(edges_df.action, prefix='action')\n",
    "\n",
    "# concatenate the dummies to the original DataFrame\n",
    "edges_df = pd.concat([edges_df, dummies], axis=1)\n",
    "\n",
    "# drop the original 'action' column\n",
    "edges_df.drop('action', axis=1, inplace=True)\n",
    "\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <th>newBalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>isUnauthorizedOverdraft</th>\n",
       "      <th>action_CASH_IN</th>\n",
       "      <th>action_CASH_OUT</th>\n",
       "      <th>action_DEBIT</th>\n",
       "      <th>action_PAYMENT</th>\n",
       "      <th>action_TRANSFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>94.57</td>\n",
       "      <td>16927</td>\n",
       "      <td>94.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66755</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>94.57</td>\n",
       "      <td>66755</td>\n",
       "      <td>94.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>84.47</td>\n",
       "      <td>32382</td>\n",
       "      <td>84.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57279</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>84.47</td>\n",
       "      <td>57279</td>\n",
       "      <td>84.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>45354</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>91.27</td>\n",
       "      <td>25464</td>\n",
       "      <td>91.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step  amount  nameOrig  oldBalanceOrig  newBalanceOrig  nameDest  \\\n",
       "0     0   94.57     16927           94.57             0.0     66755   \n",
       "1     0   94.57     66755           94.57             0.0     30632   \n",
       "2     0   84.47     32382           84.47             0.0     57279   \n",
       "3     0   84.47     57279           84.47             0.0     45354   \n",
       "4     0   91.27     25464           91.27             0.0     37868   \n",
       "\n",
       "   oldBalanceDest  newBalanceDest  isFraud  isFlaggedFraud  \\\n",
       "0             0.0           94.57        1               0   \n",
       "1             0.0            0.00        1               0   \n",
       "2             0.0           84.47        1               0   \n",
       "3             0.0            0.00        1               0   \n",
       "4             0.0           91.27        1               0   \n",
       "\n",
       "   isUnauthorizedOverdraft  action_CASH_IN  action_CASH_OUT  action_DEBIT  \\\n",
       "0                        0               0                0             0   \n",
       "1                        0               0                1             0   \n",
       "2                        0               0                0             0   \n",
       "3                        0               0                1             0   \n",
       "4                        0               0                0             0   \n",
       "\n",
       "   action_PAYMENT  action_TRANSFER  \n",
       "0               0                1  \n",
       "1               0                0  \n",
       "2               0                1  \n",
       "3               0                0  \n",
       "4               0                1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we compute numerical indices for nameOrig and nameDest rather than their form 'CC6839167080'\n",
    "\n",
    "# Create a dictionary that maps each unique original name to a new unique ID\n",
    "node_ids = {node_name: i for i, node_name in enumerate(set(edges_df['nameOrig']).union(set(edges_df['nameDest'])))}\n",
    "\n",
    "\n",
    "# Replace the original names with the new IDs\n",
    "edges_df['nameOrig'] = edges_df['nameOrig'].map(node_ids)\n",
    "edges_df['nameDest'] = edges_df['nameDest'].map(node_ids)\n",
    "\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_deg_in</th>\n",
       "      <th>node_deg_out</th>\n",
       "      <th>node_deg_total</th>\n",
       "      <th>node_min_balance</th>\n",
       "      <th>node_max_balance</th>\n",
       "      <th>node_min_new_balance</th>\n",
       "      <th>node_max_new_balance</th>\n",
       "      <th>node_mean_new_balance</th>\n",
       "      <th>node_mean_old_balance</th>\n",
       "      <th>node_std_new_balance</th>\n",
       "      <th>...</th>\n",
       "      <th>node_actions_dependent_out_function_TRANSFER</th>\n",
       "      <th>node_actions_dependent_out_function_CASHIN</th>\n",
       "      <th>node_actions_dependent_out_function_CASHOUT</th>\n",
       "      <th>node_actions_dependent_out_function_DEBIT</th>\n",
       "      <th>node_actions_dependent_out_function_PAYMENT</th>\n",
       "      <th>node_countains_flagged_fraud</th>\n",
       "      <th>node_countains_unauth_overdraft</th>\n",
       "      <th>node_in_isFraud</th>\n",
       "      <th>node_out_isFraud</th>\n",
       "      <th>node_isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>3288124.73</td>\n",
       "      <td>7149951.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>330401.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>176571.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>85860.20</td>\n",
       "      <td>4046018.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5112756.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82687</th>\n",
       "      <td>9.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>701816.04</td>\n",
       "      <td>6542649.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82688</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>119243.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82689</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>224623.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82690</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3612411.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82691</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4801859.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82692 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       node_deg_in  node_deg_out  node_deg_total  node_min_balance  \\\n",
       "0              7.0         540.0           547.0        3288124.73   \n",
       "1             94.0           0.0            94.0              0.00   \n",
       "2             95.0           0.0            95.0              0.00   \n",
       "3              5.0          34.0            39.0          85860.20   \n",
       "4              6.0           2.0             8.0              0.00   \n",
       "...            ...           ...             ...               ...   \n",
       "82687          9.0         295.0           304.0         701816.04   \n",
       "82688         81.0           0.0            81.0              0.00   \n",
       "82689         81.0           0.0            81.0              0.00   \n",
       "82690          5.0           2.0             7.0              0.00   \n",
       "82691          1.0           1.0             2.0              0.00   \n",
       "\n",
       "       node_max_balance  node_min_new_balance  node_max_new_balance  \\\n",
       "0            7149951.19                   0.0                   0.0   \n",
       "1             330401.59                   0.0                   0.0   \n",
       "2             176571.13                   0.0                   0.0   \n",
       "3            4046018.16                   0.0                   0.0   \n",
       "4            5112756.31                   0.0                   0.0   \n",
       "...                 ...                   ...                   ...   \n",
       "82687        6542649.96                   0.0                   0.0   \n",
       "82688         119243.94                   0.0                   0.0   \n",
       "82689         224623.72                   0.0                   0.0   \n",
       "82690        3612411.19                   0.0                   0.0   \n",
       "82691        4801859.06                   0.0                   0.0   \n",
       "\n",
       "       node_mean_new_balance  node_mean_old_balance  node_std_new_balance  \\\n",
       "0                        0.0                    0.0                   0.0   \n",
       "1                        0.0                    0.0                   0.0   \n",
       "2                        0.0                    0.0                   0.0   \n",
       "3                        0.0                    0.0                   0.0   \n",
       "4                        0.0                    0.0                   0.0   \n",
       "...                      ...                    ...                   ...   \n",
       "82687                    0.0                    0.0                   0.0   \n",
       "82688                    0.0                    0.0                   0.0   \n",
       "82689                    0.0                    0.0                   0.0   \n",
       "82690                    0.0                    0.0                   0.0   \n",
       "82691                    0.0                    0.0                   0.0   \n",
       "\n",
       "       ...  node_actions_dependent_out_function_TRANSFER  \\\n",
       "0      ...                                      0.999961   \n",
       "1      ...                                      0.000000   \n",
       "2      ...                                      0.000000   \n",
       "3      ...                                      0.997815   \n",
       "4      ...                                      0.000000   \n",
       "...    ...                                           ...   \n",
       "82687  ...                                      0.999970   \n",
       "82688  ...                                      0.000000   \n",
       "82689  ...                                      0.000000   \n",
       "82690  ...                                      0.000000   \n",
       "82691  ...                                      0.000000   \n",
       "\n",
       "       node_actions_dependent_out_function_CASHIN  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "...                                           ...   \n",
       "82687                                         0.0   \n",
       "82688                                         0.0   \n",
       "82689                                         0.0   \n",
       "82690                                         0.0   \n",
       "82691                                         0.0   \n",
       "\n",
       "       node_actions_dependent_out_function_CASHOUT  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "...                                            ...   \n",
       "82687                                          0.0   \n",
       "82688                                          0.0   \n",
       "82689                                          0.0   \n",
       "82690                                          0.0   \n",
       "82691                                          0.0   \n",
       "\n",
       "       node_actions_dependent_out_function_DEBIT  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "...                                          ...   \n",
       "82687                                        0.0   \n",
       "82688                                        0.0   \n",
       "82689                                        0.0   \n",
       "82690                                        0.0   \n",
       "82691                                        0.0   \n",
       "\n",
       "       node_actions_dependent_out_function_PAYMENT  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "...                                            ...   \n",
       "82687                                          0.0   \n",
       "82688                                          0.0   \n",
       "82689                                          0.0   \n",
       "82690                                          0.0   \n",
       "82691                                          0.0   \n",
       "\n",
       "       node_countains_flagged_fraud  node_countains_unauth_overdraft  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              1.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                              0.0   \n",
       "4                               0.0                              0.0   \n",
       "...                             ...                              ...   \n",
       "82687                           0.0                              1.0   \n",
       "82688                           0.0                              1.0   \n",
       "82689                           0.0                              0.0   \n",
       "82690                           0.0                              0.0   \n",
       "82691                           0.0                              0.0   \n",
       "\n",
       "       node_in_isFraud  node_out_isFraud  node_isFraud  \n",
       "0                  0.0               1.0           0.0  \n",
       "1                  1.0               0.0           0.0  \n",
       "2                  0.0               0.0           0.0  \n",
       "3                  0.0               1.0           0.0  \n",
       "4                  1.0               1.0           1.0  \n",
       "...                ...               ...           ...  \n",
       "82687              0.0               0.0           0.0  \n",
       "82688              1.0               0.0           0.0  \n",
       "82689              1.0               0.0           0.0  \n",
       "82690              1.0               1.0           1.0  \n",
       "82691              1.0               1.0           1.0  \n",
       "\n",
       "[82692 rows x 44 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82692, 41)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np = nodes_df.to_numpy()\n",
    "x = x_np[:,0:-3]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2, learning_rate='auto',\n",
    "             init='random').fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()\n",
    "\n",
    "def print_model_size(model):\n",
    "    tot = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "    out = f\"Number of model ({model.__class__.__name__}) parameters:{tot:10d}\"\n",
    "    print(\"=\" * len(out))\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "# Define your graph\n",
    "x = torch.nn.functional.normalize(torch.tensor(x),dim=0).to(torch.float32)  # (n x features)\n",
    "edge_index =  torch.stack([torch.tensor(edges_df.nameOrig.to_numpy()),torch.tensor(edges_df.nameDest.to_numpy())],dim=-1).T  # Define your edge index\n",
    "edge_attr = torch.nn.functional.normalize(torch.tensor(np.array(edges_df[['amount','oldBalanceOrig', 'newBalanceOrig', 'oldBalanceDest', 'newBalanceDest','isFlaggedFraud','isUnauthorizedOverdraft','action_CASH_IN','action_CASH_OUT','action_DEBIT','action_PAYMENT','action_TRANSFER']].values,dtype='float32')),dim=0) # edge features\n",
    "y =  torch.tensor(nodes_df.node_isFraud.to_numpy().astype(int)) # target values\n",
    "\n",
    "train_size = int(0.6 * len(y))  # 60% of the dataset for training\n",
    "val_size = int(0.2 * len(y))    # 20% of the dataset for validation\n",
    "test_size = len(y) - train_size - val_size  # Remaining 20% for testing\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(y, [train_size, val_size, test_size])\n",
    "\n",
    "# Create masks for train, validation, and test sets\n",
    "train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "val_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "\n",
    "train_mask[train_dataset.indices] = True\n",
    "val_mask[val_dataset.indices] = True\n",
    "test_mask[test_dataset.indices] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "# Load your data into PyTorch Geometric's Data class\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y,train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 82692\n",
      "Number of edges: 3491520\n",
      "Average node degree: 42.22\n",
      "==============================\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n",
      "Is weighted: False\n",
      "==============================\n",
      "Number of training nodes: 49615\n",
      "Training node label rate: 0.60\n"
     ]
    }
   ],
   "source": [
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "\n",
    "print('==============================')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "print(f'Is weighted: {data.edge_weight is not None}')\n",
    "\n",
    "print('==============================')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "def random_walk_matrix(edge_index, num_nodes: int = None):\n",
    "    source, target = edge_index[0], edge_index[1]\n",
    "    in_deg = degree(target, num_nodes=num_nodes)   # D\n",
    "    edge_weight = 1 / in_deg[target]               # D^-1 A\n",
    "    return edge_index, edge_weight\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge weights: tensor([0.1000, 0.0108, 0.1250,  ..., 0.0100, 1.0000, 0.0109])\n",
      "tensor([[16927, 66755, 32382,  ..., 51542,  1192, 67981],\n",
      "        [66755, 30632, 57279,  ..., 20363, 67981, 40060]])\n"
     ]
    }
   ],
   "source": [
    "gso_index, gso_weight = random_walk_matrix(data.edge_index, data.num_nodes)\n",
    "print(f\"Edge weights: {gso_weight}\")\n",
    "print(gso_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNModel(\n",
      "  (convs): ModuleList(\n",
      "    (0): SAGEConv(41, 16, aggr=mean)\n",
      "    (1): SAGEConv(16, 16, aggr=mean)\n",
      "  )\n",
      "  (lin_out): Linear(in_features=16, out_features=2, bias=True)\n",
      ")\n",
      "================================================\n",
      "Number of model (GNNModel) parameters:      1890\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torch.nn import Linear, ReLU, Dropout\n",
    "from torch_geometric.nn import Sequential, SAGEConv\n",
    "\n",
    "HIDDEN_SIZE = 16 #@param\n",
    "NUM_LAYERS = 2 #@param\n",
    "\n",
    "dataset_num_node_features = x.size(1)\n",
    "dataset_num_edge_features = edge_attr.size(1)\n",
    "dataset_num_classes = 2\n",
    "\n",
    "class GNNModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size: int,\n",
    "                 num_layers: int = 1):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for l in range(num_layers):\n",
    "            #in_size = dataset_num_features if l == 0 else hidden_size\n",
    "            in_size = dataset_num_node_features if l == 0 else hidden_size\n",
    "            in_size2 = hidden_size + dataset_num_node_features + dataset_num_edge_features if l == 0 else hidden_size*2 + dataset_num_edge_features\n",
    "            conv = SAGEConv(in_channels=in_size, out_channels=hidden_size)\n",
    "            \n",
    "            #mpnn = MPNN(in_channels=in_size, out_channels=hidden_size, in_channels2=in_size2)\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin_out = Linear(hidden_size, dataset_num_classes)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        # Message-passing: transform node features based on neighbors\n",
    "        relu = ReLU(inplace=True)\n",
    "        dropout = Dropout(p=0.2,inplace=True)\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            #x = dropout(x)\n",
    "            x = relu(x)\n",
    "            #x = conv(x, edge_index, edge_attr=edge_attr)\n",
    "        # Decoder: post-process extracted features\n",
    "        out = self.lin_out(x)\n",
    "        return out\n",
    "\n",
    "model = GNNModel(HIDDEN_SIZE, NUM_LAYERS)\n",
    "print(model)\n",
    "print_model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNNModel(HIDDEN_SIZE, NUM_LAYERS)\n",
    "model.eval()\n",
    "\n",
    "out = model(data.x, data.edge_index)\n",
    "#visualize(out, color=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "google.colab.output.setIframeHeight(0, true, {maxHeight: 100})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 - Training loss: 0.7105 - Validation accuracy: 33.58%\n",
      "Epoch: 002 - Training loss: 0.7027 - Validation accuracy: 33.59%\n",
      "Epoch: 003 - Training loss: 0.6949 - Validation accuracy: 66.42%\n",
      "Epoch: 004 - Training loss: 0.6873 - Validation accuracy: 66.42%\n",
      "Epoch: 005 - Training loss: 0.6798 - Validation accuracy: 66.42%\n",
      "Epoch: 006 - Training loss: 0.6725 - Validation accuracy: 66.42%\n",
      "Epoch: 007 - Training loss: 0.6653 - Validation accuracy: 66.42%\n",
      "Epoch: 008 - Training loss: 0.6584 - Validation accuracy: 66.42%\n",
      "Epoch: 009 - Training loss: 0.6522 - Validation accuracy: 66.42%\n",
      "Epoch: 010 - Training loss: 0.6468 - Validation accuracy: 66.42%\n",
      "Epoch: 011 - Training loss: 0.6425 - Validation accuracy: 66.42%\n",
      "Epoch: 012 - Training loss: 0.6398 - Validation accuracy: 66.42%\n",
      "Epoch: 013 - Training loss: 0.6389 - Validation accuracy: 66.42%\n",
      "Epoch: 014 - Training loss: 0.6398 - Validation accuracy: 66.42%\n",
      "Epoch: 015 - Training loss: 0.6419 - Validation accuracy: 66.42%\n",
      "Epoch: 016 - Training loss: 0.6437 - Validation accuracy: 66.42%\n",
      "Epoch: 017 - Training loss: 0.6446 - Validation accuracy: 66.42%\n",
      "Epoch: 018 - Training loss: 0.6442 - Validation accuracy: 66.42%\n",
      "Epoch: 019 - Training loss: 0.6430 - Validation accuracy: 66.42%\n",
      "Epoch: 020 - Training loss: 0.6412 - Validation accuracy: 66.42%\n",
      "Epoch: 021 - Training loss: 0.6396 - Validation accuracy: 66.42%\n",
      "Epoch: 022 - Training loss: 0.6382 - Validation accuracy: 66.42%\n",
      "Epoch: 023 - Training loss: 0.6375 - Validation accuracy: 66.42%\n",
      "Epoch: 024 - Training loss: 0.6375 - Validation accuracy: 66.42%\n",
      "Epoch: 025 - Training loss: 0.6378 - Validation accuracy: 66.42%\n",
      "Epoch: 026 - Training loss: 0.6382 - Validation accuracy: 66.42%\n",
      "Epoch: 027 - Training loss: 0.6382 - Validation accuracy: 66.42%\n",
      "Epoch: 028 - Training loss: 0.6379 - Validation accuracy: 66.42%\n",
      "Epoch: 029 - Training loss: 0.6374 - Validation accuracy: 66.42%\n",
      "Epoch: 030 - Training loss: 0.6369 - Validation accuracy: 66.42%\n",
      "Epoch: 031 - Training loss: 0.6364 - Validation accuracy: 66.42%\n",
      "Epoch: 032 - Training loss: 0.6359 - Validation accuracy: 66.42%\n",
      "Epoch: 033 - Training loss: 0.6356 - Validation accuracy: 66.42%\n",
      "Epoch: 034 - Training loss: 0.6352 - Validation accuracy: 66.42%\n",
      "Epoch: 035 - Training loss: 0.6350 - Validation accuracy: 66.42%\n",
      "Epoch: 036 - Training loss: 0.6347 - Validation accuracy: 66.42%\n",
      "Epoch: 037 - Training loss: 0.6344 - Validation accuracy: 66.42%\n",
      "Epoch: 038 - Training loss: 0.6340 - Validation accuracy: 66.42%\n",
      "Epoch: 039 - Training loss: 0.6335 - Validation accuracy: 66.42%\n",
      "Epoch: 040 - Training loss: 0.6329 - Validation accuracy: 66.42%\n",
      "Epoch: 041 - Training loss: 0.6322 - Validation accuracy: 66.42%\n",
      "Epoch: 042 - Training loss: 0.6314 - Validation accuracy: 66.42%\n",
      "Epoch: 043 - Training loss: 0.6305 - Validation accuracy: 66.42%\n",
      "Epoch: 044 - Training loss: 0.6295 - Validation accuracy: 66.42%\n",
      "Epoch: 045 - Training loss: 0.6287 - Validation accuracy: 66.42%\n",
      "Epoch: 046 - Training loss: 0.6272 - Validation accuracy: 66.42%\n",
      "Epoch: 047 - Training loss: 0.6259 - Validation accuracy: 66.42%\n",
      "Epoch: 048 - Training loss: 0.6244 - Validation accuracy: 66.42%\n",
      "Epoch: 049 - Training loss: 0.6227 - Validation accuracy: 66.42%\n",
      "Epoch: 050 - Training loss: 0.6208 - Validation accuracy: 66.42%\n",
      "Epoch: 051 - Training loss: 0.6186 - Validation accuracy: 66.42%\n",
      "Epoch: 052 - Training loss: 0.6162 - Validation accuracy: 66.42%\n",
      "Epoch: 053 - Training loss: 0.6135 - Validation accuracy: 66.42%\n",
      "Epoch: 054 - Training loss: 0.6105 - Validation accuracy: 66.42%\n",
      "Epoch: 055 - Training loss: 0.6072 - Validation accuracy: 66.42%\n",
      "Epoch: 056 - Training loss: 0.6034 - Validation accuracy: 66.42%\n",
      "Epoch: 057 - Training loss: 0.5992 - Validation accuracy: 66.42%\n",
      "Epoch: 058 - Training loss: 0.5946 - Validation accuracy: 66.42%\n",
      "Epoch: 059 - Training loss: 0.5895 - Validation accuracy: 66.42%\n",
      "Epoch: 060 - Training loss: 0.5839 - Validation accuracy: 66.42%\n",
      "Epoch: 061 - Training loss: 0.5777 - Validation accuracy: 66.42%\n",
      "Epoch: 062 - Training loss: 0.5711 - Validation accuracy: 66.42%\n",
      "Epoch: 063 - Training loss: 0.5638 - Validation accuracy: 66.42%\n",
      "Epoch: 064 - Training loss: 0.5560 - Validation accuracy: 66.42%\n",
      "Epoch: 065 - Training loss: 0.5475 - Validation accuracy: 66.53%\n",
      "Epoch: 066 - Training loss: 0.5384 - Validation accuracy: 67.01%\n",
      "Epoch: 067 - Training loss: 0.5287 - Validation accuracy: 67.72%\n",
      "Epoch: 068 - Training loss: 0.5185 - Validation accuracy: 68.58%\n",
      "Epoch: 069 - Training loss: 0.5078 - Validation accuracy: 69.30%\n",
      "Epoch: 070 - Training loss: 0.4966 - Validation accuracy: 70.98%\n",
      "Epoch: 071 - Training loss: 0.4850 - Validation accuracy: 74.38%\n",
      "Epoch: 072 - Training loss: 0.4732 - Validation accuracy: 75.00%\n",
      "Epoch: 073 - Training loss: 0.4612 - Validation accuracy: 80.32%\n",
      "Epoch: 074 - Training loss: 0.4492 - Validation accuracy: 78.42%\n",
      "Epoch: 075 - Training loss: 0.4372 - Validation accuracy: 85.31%\n",
      "Epoch: 076 - Training loss: 0.4253 - Validation accuracy: 82.92%\n",
      "Epoch: 077 - Training loss: 0.4132 - Validation accuracy: 86.07%\n",
      "Epoch: 078 - Training loss: 0.4013 - Validation accuracy: 87.89%\n",
      "Epoch: 079 - Training loss: 0.3901 - Validation accuracy: 86.25%\n",
      "Epoch: 080 - Training loss: 0.3795 - Validation accuracy: 88.82%\n",
      "Epoch: 081 - Training loss: 0.3690 - Validation accuracy: 88.31%\n",
      "Epoch: 082 - Training loss: 0.3585 - Validation accuracy: 89.00%\n",
      "Epoch: 083 - Training loss: 0.3489 - Validation accuracy: 89.01%\n",
      "Epoch: 084 - Training loss: 0.3401 - Validation accuracy: 89.03%\n",
      "Epoch: 085 - Training loss: 0.3317 - Validation accuracy: 89.38%\n",
      "Epoch: 086 - Training loss: 0.3233 - Validation accuracy: 89.93%\n",
      "Epoch: 087 - Training loss: 0.3152 - Validation accuracy: 90.02%\n",
      "Epoch: 088 - Training loss: 0.3081 - Validation accuracy: 89.70%\n",
      "Epoch: 089 - Training loss: 0.3015 - Validation accuracy: 90.37%\n",
      "Epoch: 090 - Training loss: 0.2948 - Validation accuracy: 90.39%\n",
      "Epoch: 091 - Training loss: 0.2881 - Validation accuracy: 90.72%\n",
      "Epoch: 092 - Training loss: 0.2819 - Validation accuracy: 91.18%\n",
      "Epoch: 093 - Training loss: 0.2765 - Validation accuracy: 90.89%\n",
      "Epoch: 094 - Training loss: 0.2712 - Validation accuracy: 91.56%\n",
      "Epoch: 095 - Training loss: 0.2657 - Validation accuracy: 91.62%\n",
      "Epoch: 096 - Training loss: 0.2601 - Validation accuracy: 91.92%\n",
      "Epoch: 097 - Training loss: 0.2550 - Validation accuracy: 92.09%\n",
      "Epoch: 098 - Training loss: 0.2505 - Validation accuracy: 92.19%\n",
      "Epoch: 099 - Training loss: 0.2462 - Validation accuracy: 92.41%\n",
      "Epoch: 100 - Training loss: 0.2417 - Validation accuracy: 92.85%\n",
      "Epoch: 101 - Training loss: 0.2369 - Validation accuracy: 93.02%\n",
      "Epoch: 102 - Training loss: 0.2325 - Validation accuracy: 93.01%\n",
      "Epoch: 103 - Training loss: 0.2286 - Validation accuracy: 93.04%\n",
      "Epoch: 104 - Training loss: 0.2249 - Validation accuracy: 93.25%\n",
      "Epoch: 105 - Training loss: 0.2213 - Validation accuracy: 93.36%\n",
      "Epoch: 106 - Training loss: 0.2173 - Validation accuracy: 93.83%\n",
      "Epoch: 107 - Training loss: 0.2134 - Validation accuracy: 93.95%\n",
      "Epoch: 108 - Training loss: 0.2098 - Validation accuracy: 93.59%\n",
      "Epoch: 109 - Training loss: 0.2067 - Validation accuracy: 94.23%\n",
      "Epoch: 110 - Training loss: 0.2038 - Validation accuracy: 93.57%\n",
      "Epoch: 111 - Training loss: 0.2006 - Validation accuracy: 94.38%\n",
      "Epoch: 112 - Training loss: 0.1973 - Validation accuracy: 94.04%\n",
      "Epoch: 113 - Training loss: 0.1941 - Validation accuracy: 94.07%\n",
      "Epoch: 114 - Training loss: 0.1911 - Validation accuracy: 94.40%\n",
      "Epoch: 115 - Training loss: 0.1886 - Validation accuracy: 93.85%\n",
      "Epoch: 116 - Training loss: 0.1861 - Validation accuracy: 94.67%\n",
      "Epoch: 117 - Training loss: 0.1837 - Validation accuracy: 93.95%\n",
      "Epoch: 118 - Training loss: 0.1810 - Validation accuracy: 94.47%\n",
      "Epoch: 119 - Training loss: 0.1783 - Validation accuracy: 94.31%\n",
      "Epoch: 120 - Training loss: 0.1756 - Validation accuracy: 94.37%\n",
      "Epoch: 121 - Training loss: 0.1733 - Validation accuracy: 94.61%\n",
      "Epoch: 122 - Training loss: 0.1712 - Validation accuracy: 94.21%\n",
      "Epoch: 123 - Training loss: 0.1693 - Validation accuracy: 94.90%\n",
      "Epoch: 124 - Training loss: 0.1674 - Validation accuracy: 94.21%\n",
      "Epoch: 125 - Training loss: 0.1654 - Validation accuracy: 94.87%\n",
      "Epoch: 126 - Training loss: 0.1631 - Validation accuracy: 94.53%\n",
      "Epoch: 127 - Training loss: 0.1608 - Validation accuracy: 94.71%\n",
      "Epoch: 128 - Training loss: 0.1587 - Validation accuracy: 94.89%\n",
      "Epoch: 129 - Training loss: 0.1570 - Validation accuracy: 94.56%\n",
      "Epoch: 130 - Training loss: 0.1555 - Validation accuracy: 95.02%\n",
      "Epoch: 131 - Training loss: 0.1541 - Validation accuracy: 94.56%\n",
      "Epoch: 132 - Training loss: 0.1526 - Validation accuracy: 95.07%\n",
      "Epoch: 133 - Training loss: 0.1508 - Validation accuracy: 94.78%\n",
      "Epoch: 134 - Training loss: 0.1489 - Validation accuracy: 95.06%\n",
      "Epoch: 135 - Training loss: 0.1471 - Validation accuracy: 95.10%\n",
      "Epoch: 136 - Training loss: 0.1457 - Validation accuracy: 94.89%\n",
      "Epoch: 137 - Training loss: 0.1445 - Validation accuracy: 95.11%\n",
      "Epoch: 138 - Training loss: 0.1434 - Validation accuracy: 94.84%\n",
      "Epoch: 139 - Training loss: 0.1423 - Validation accuracy: 95.15%\n",
      "Epoch: 140 - Training loss: 0.1410 - Validation accuracy: 94.97%\n",
      "Epoch: 141 - Training loss: 0.1396 - Validation accuracy: 95.21%\n",
      "Epoch: 142 - Training loss: 0.1380 - Validation accuracy: 95.36%\n",
      "Epoch: 143 - Training loss: 0.1367 - Validation accuracy: 95.33%\n",
      "Epoch: 144 - Training loss: 0.1357 - Validation accuracy: 95.21%\n",
      "Epoch: 145 - Training loss: 0.1348 - Validation accuracy: 95.18%\n",
      "Epoch: 146 - Training loss: 0.1341 - Validation accuracy: 95.25%\n",
      "Epoch: 147 - Training loss: 0.1333 - Validation accuracy: 95.19%\n",
      "Epoch: 148 - Training loss: 0.1324 - Validation accuracy: 95.31%\n",
      "Epoch: 149 - Training loss: 0.1313 - Validation accuracy: 95.39%\n",
      "Epoch: 150 - Training loss: 0.1300 - Validation accuracy: 95.48%\n",
      "Epoch: 151 - Training loss: 0.1289 - Validation accuracy: 95.53%\n",
      "Epoch: 152 - Training loss: 0.1280 - Validation accuracy: 95.52%\n",
      "Epoch: 153 - Training loss: 0.1274 - Validation accuracy: 95.45%\n",
      "Epoch: 154 - Training loss: 0.1269 - Validation accuracy: 95.37%\n",
      "Epoch: 155 - Training loss: 0.1264 - Validation accuracy: 95.43%\n",
      "Epoch: 156 - Training loss: 0.1259 - Validation accuracy: 95.42%\n",
      "Epoch: 157 - Training loss: 0.1252 - Validation accuracy: 95.53%\n",
      "Epoch: 158 - Training loss: 0.1243 - Validation accuracy: 95.66%\n",
      "Epoch: 159 - Training loss: 0.1233 - Validation accuracy: 95.60%\n",
      "Epoch: 160 - Training loss: 0.1224 - Validation accuracy: 95.62%\n",
      "Epoch: 161 - Training loss: 0.1218 - Validation accuracy: 95.70%\n",
      "Epoch: 162 - Training loss: 0.1214 - Validation accuracy: 95.63%\n",
      "Epoch: 163 - Training loss: 0.1211 - Validation accuracy: 95.66%\n",
      "Epoch: 164 - Training loss: 0.1208 - Validation accuracy: 95.72%\n",
      "Epoch: 165 - Training loss: 0.1205 - Validation accuracy: 95.62%\n",
      "Epoch: 166 - Training loss: 0.1199 - Validation accuracy: 95.79%\n",
      "Epoch: 167 - Training loss: 0.1192 - Validation accuracy: 95.73%\n",
      "Epoch: 168 - Training loss: 0.1183 - Validation accuracy: 95.75%\n",
      "Epoch: 169 - Training loss: 0.1176 - Validation accuracy: 95.76%\n",
      "Epoch: 170 - Training loss: 0.1172 - Validation accuracy: 95.82%\n",
      "Epoch: 171 - Training loss: 0.1169 - Validation accuracy: 95.79%\n",
      "Epoch: 172 - Training loss: 0.1167 - Validation accuracy: 95.75%\n",
      "Epoch: 173 - Training loss: 0.1166 - Validation accuracy: 95.82%\n",
      "Epoch: 174 - Training loss: 0.1164 - Validation accuracy: 95.76%\n",
      "Epoch: 175 - Training loss: 0.1160 - Validation accuracy: 95.88%\n",
      "Epoch: 176 - Training loss: 0.1155 - Validation accuracy: 95.91%\n",
      "Epoch: 177 - Training loss: 0.1148 - Validation accuracy: 95.89%\n",
      "Epoch: 178 - Training loss: 0.1141 - Validation accuracy: 95.89%\n",
      "Epoch: 179 - Training loss: 0.1137 - Validation accuracy: 95.92%\n",
      "Epoch: 180 - Training loss: 0.1134 - Validation accuracy: 95.93%\n",
      "Epoch: 181 - Training loss: 0.1133 - Validation accuracy: 95.95%\n",
      "Epoch: 182 - Training loss: 0.1132 - Validation accuracy: 95.95%\n",
      "Epoch: 183 - Training loss: 0.1131 - Validation accuracy: 95.89%\n",
      "Epoch: 184 - Training loss: 0.1130 - Validation accuracy: 95.95%\n",
      "Epoch: 185 - Training loss: 0.1127 - Validation accuracy: 95.91%\n",
      "Epoch: 186 - Training loss: 0.1123 - Validation accuracy: 95.97%\n",
      "Epoch: 187 - Training loss: 0.1117 - Validation accuracy: 96.03%\n",
      "Epoch: 188 - Training loss: 0.1111 - Validation accuracy: 95.98%\n",
      "Epoch: 189 - Training loss: 0.1107 - Validation accuracy: 95.99%\n",
      "Epoch: 190 - Training loss: 0.1105 - Validation accuracy: 96.05%\n",
      "Epoch: 191 - Training loss: 0.1104 - Validation accuracy: 96.04%\n",
      "Epoch: 192 - Training loss: 0.1104 - Validation accuracy: 96.00%\n",
      "Epoch: 193 - Training loss: 0.1104 - Validation accuracy: 96.05%\n",
      "Epoch: 194 - Training loss: 0.1103 - Validation accuracy: 95.96%\n",
      "Epoch: 195 - Training loss: 0.1102 - Validation accuracy: 96.04%\n",
      "Epoch: 196 - Training loss: 0.1099 - Validation accuracy: 96.02%\n",
      "Epoch: 197 - Training loss: 0.1095 - Validation accuracy: 96.06%\n",
      "Epoch: 198 - Training loss: 0.1090 - Validation accuracy: 96.03%\n",
      "Epoch: 199 - Training loss: 0.1086 - Validation accuracy: 96.05%\n",
      "Epoch: 200 - Training loss: 0.1083 - Validation accuracy: 96.08%\n",
      "Epoch: 201 - Training loss: 0.1081 - Validation accuracy: 96.03%\n",
      "Epoch: 202 - Training loss: 0.1081 - Validation accuracy: 96.09%\n",
      "Epoch: 203 - Training loss: 0.1081 - Validation accuracy: 96.08%\n",
      "Epoch: 204 - Training loss: 0.1081 - Validation accuracy: 96.06%\n",
      "Epoch: 205 - Training loss: 0.1081 - Validation accuracy: 96.02%\n",
      "Epoch: 206 - Training loss: 0.1081 - Validation accuracy: 96.05%\n",
      "Epoch: 207 - Training loss: 0.1080 - Validation accuracy: 96.03%\n",
      "Epoch: 208 - Training loss: 0.1077 - Validation accuracy: 96.08%\n",
      "Epoch: 209 - Training loss: 0.1073 - Validation accuracy: 96.11%\n",
      "Epoch: 210 - Training loss: 0.1069 - Validation accuracy: 96.15%\n",
      "Epoch: 211 - Training loss: 0.1065 - Validation accuracy: 96.14%\n",
      "Epoch: 212 - Training loss: 0.1063 - Validation accuracy: 96.03%\n",
      "Epoch: 213 - Training loss: 0.1062 - Validation accuracy: 96.15%\n",
      "Epoch: 214 - Training loss: 0.1062 - Validation accuracy: 96.14%\n",
      "Epoch: 215 - Training loss: 0.1063 - Validation accuracy: 96.08%\n",
      "Epoch: 216 - Training loss: 0.1063 - Validation accuracy: 96.05%\n",
      "Epoch: 217 - Training loss: 0.1064 - Validation accuracy: 96.06%\n",
      "Epoch: 218 - Training loss: 0.1064 - Validation accuracy: 96.08%\n",
      "Epoch: 219 - Training loss: 0.1063 - Validation accuracy: 96.07%\n",
      "Epoch: 220 - Training loss: 0.1061 - Validation accuracy: 96.08%\n",
      "Epoch: 221 - Training loss: 0.1058 - Validation accuracy: 96.13%\n",
      "Epoch: 222 - Training loss: 0.1054 - Validation accuracy: 96.11%\n",
      "Epoch: 223 - Training loss: 0.1050 - Validation accuracy: 96.20%\n",
      "Epoch: 224 - Training loss: 0.1048 - Validation accuracy: 96.20%\n",
      "Epoch: 225 - Training loss: 0.1047 - Validation accuracy: 96.12%\n",
      "Epoch: 226 - Training loss: 0.1047 - Validation accuracy: 96.17%\n",
      "Epoch: 227 - Training loss: 0.1047 - Validation accuracy: 96.14%\n",
      "Epoch: 228 - Training loss: 0.1048 - Validation accuracy: 96.08%\n",
      "Epoch: 229 - Training loss: 0.1049 - Validation accuracy: 96.11%\n",
      "Epoch: 230 - Training loss: 0.1049 - Validation accuracy: 96.04%\n",
      "Epoch: 231 - Training loss: 0.1049 - Validation accuracy: 96.09%\n",
      "Epoch: 232 - Training loss: 0.1049 - Validation accuracy: 96.05%\n",
      "Epoch: 233 - Training loss: 0.1047 - Validation accuracy: 96.12%\n",
      "Epoch: 234 - Training loss: 0.1044 - Validation accuracy: 96.18%\n",
      "Epoch: 235 - Training loss: 0.1040 - Validation accuracy: 96.15%\n",
      "Epoch: 236 - Training loss: 0.1037 - Validation accuracy: 96.23%\n",
      "Epoch: 237 - Training loss: 0.1035 - Validation accuracy: 96.23%\n",
      "Epoch: 238 - Training loss: 0.1034 - Validation accuracy: 96.19%\n",
      "Epoch: 239 - Training loss: 0.1034 - Validation accuracy: 96.21%\n",
      "Epoch: 240 - Training loss: 0.1035 - Validation accuracy: 96.15%\n",
      "Epoch: 241 - Training loss: 0.1035 - Validation accuracy: 96.12%\n",
      "Epoch: 242 - Training loss: 0.1036 - Validation accuracy: 96.14%\n",
      "Epoch: 243 - Training loss: 0.1037 - Validation accuracy: 96.11%\n",
      "Epoch: 244 - Training loss: 0.1037 - Validation accuracy: 96.13%\n",
      "Epoch: 245 - Training loss: 0.1037 - Validation accuracy: 96.09%\n",
      "Epoch: 246 - Training loss: 0.1036 - Validation accuracy: 96.17%\n",
      "Epoch: 247 - Training loss: 0.1034 - Validation accuracy: 96.21%\n",
      "Epoch: 248 - Training loss: 0.1030 - Validation accuracy: 96.15%\n",
      "Epoch: 249 - Training loss: 0.1028 - Validation accuracy: 96.24%\n",
      "Epoch: 250 - Training loss: 0.1025 - Validation accuracy: 96.26%\n",
      "Epoch: 251 - Training loss: 0.1024 - Validation accuracy: 96.22%\n",
      "Epoch: 252 - Training loss: 0.1023 - Validation accuracy: 96.23%\n",
      "Epoch: 253 - Training loss: 0.1023 - Validation accuracy: 96.18%\n",
      "Epoch: 254 - Training loss: 0.1024 - Validation accuracy: 96.24%\n",
      "Epoch: 255 - Training loss: 0.1024 - Validation accuracy: 96.17%\n",
      "Epoch: 256 - Training loss: 0.1025 - Validation accuracy: 96.17%\n",
      "Epoch: 257 - Training loss: 0.1026 - Validation accuracy: 96.20%\n",
      "Epoch: 258 - Training loss: 0.1027 - Validation accuracy: 96.10%\n",
      "Epoch: 259 - Training loss: 0.1027 - Validation accuracy: 96.16%\n",
      "Epoch: 260 - Training loss: 0.1027 - Validation accuracy: 96.15%\n",
      "Epoch: 261 - Training loss: 0.1026 - Validation accuracy: 96.23%\n",
      "Epoch: 262 - Training loss: 0.1023 - Validation accuracy: 96.22%\n",
      "Epoch: 263 - Training loss: 0.1019 - Validation accuracy: 96.26%\n",
      "Epoch: 264 - Training loss: 0.1016 - Validation accuracy: 96.31%\n",
      "Epoch: 265 - Training loss: 0.1014 - Validation accuracy: 96.31%\n",
      "Epoch: 266 - Training loss: 0.1013 - Validation accuracy: 96.25%\n",
      "Epoch: 267 - Training loss: 0.1013 - Validation accuracy: 96.23%\n",
      "Epoch: 268 - Training loss: 0.1014 - Validation accuracy: 96.20%\n",
      "Epoch: 269 - Training loss: 0.1015 - Validation accuracy: 96.25%\n",
      "Epoch: 270 - Training loss: 0.1016 - Validation accuracy: 96.25%\n",
      "Epoch: 271 - Training loss: 0.1017 - Validation accuracy: 96.23%\n",
      "Epoch: 272 - Training loss: 0.1017 - Validation accuracy: 96.23%\n",
      "Epoch: 273 - Training loss: 0.1017 - Validation accuracy: 96.23%\n",
      "Epoch: 274 - Training loss: 0.1016 - Validation accuracy: 96.26%\n",
      "Epoch: 275 - Training loss: 0.1015 - Validation accuracy: 96.24%\n",
      "Epoch: 276 - Training loss: 0.1012 - Validation accuracy: 96.21%\n",
      "Epoch: 277 - Training loss: 0.1010 - Validation accuracy: 96.28%\n",
      "Epoch: 278 - Training loss: 0.1008 - Validation accuracy: 96.28%\n",
      "Epoch: 279 - Training loss: 0.1006 - Validation accuracy: 96.34%\n",
      "Epoch: 280 - Training loss: 0.1005 - Validation accuracy: 96.34%\n",
      "Epoch: 281 - Training loss: 0.1005 - Validation accuracy: 96.28%\n",
      "Epoch: 282 - Training loss: 0.1005 - Validation accuracy: 96.31%\n",
      "Epoch: 283 - Training loss: 0.1005 - Validation accuracy: 96.28%\n",
      "Epoch: 284 - Training loss: 0.1005 - Validation accuracy: 96.31%\n",
      "Epoch: 285 - Training loss: 0.1006 - Validation accuracy: 96.25%\n",
      "Epoch: 286 - Training loss: 0.1007 - Validation accuracy: 96.26%\n",
      "Epoch: 287 - Training loss: 0.1008 - Validation accuracy: 96.17%\n",
      "Epoch: 288 - Training loss: 0.1011 - Validation accuracy: 96.20%\n",
      "Epoch: 289 - Training loss: 0.1013 - Validation accuracy: 96.18%\n",
      "Epoch: 290 - Training loss: 0.1016 - Validation accuracy: 96.17%\n",
      "Epoch: 291 - Training loss: 0.1016 - Validation accuracy: 96.17%\n",
      "Epoch: 292 - Training loss: 0.1015 - Validation accuracy: 96.20%\n",
      "Epoch: 293 - Training loss: 0.1010 - Validation accuracy: 96.28%\n",
      "Epoch: 294 - Training loss: 0.1004 - Validation accuracy: 96.33%\n",
      "Epoch: 295 - Training loss: 0.0999 - Validation accuracy: 96.34%\n",
      "Epoch: 296 - Training loss: 0.0997 - Validation accuracy: 96.26%\n",
      "Epoch: 297 - Training loss: 0.0999 - Validation accuracy: 96.29%\n",
      "Epoch: 298 - Training loss: 0.1001 - Validation accuracy: 96.26%\n",
      "Epoch: 299 - Training loss: 0.1004 - Validation accuracy: 96.28%\n",
      "Epoch: 300 - Training loss: 0.1004 - Validation accuracy: 96.27%\n",
      "Epoch: 301 - Training loss: 0.1002 - Validation accuracy: 96.30%\n",
      "Epoch: 302 - Training loss: 0.0999 - Validation accuracy: 96.29%\n",
      "Epoch: 303 - Training loss: 0.0996 - Validation accuracy: 96.36%\n",
      "Epoch: 304 - Training loss: 0.0994 - Validation accuracy: 96.38%\n",
      "Epoch: 305 - Training loss: 0.0994 - Validation accuracy: 96.29%\n",
      "Epoch: 306 - Training loss: 0.0995 - Validation accuracy: 96.29%\n",
      "Epoch: 307 - Training loss: 0.0996 - Validation accuracy: 96.28%\n",
      "Epoch: 308 - Training loss: 0.0997 - Validation accuracy: 96.34%\n",
      "Epoch: 309 - Training loss: 0.0996 - Validation accuracy: 96.28%\n",
      "Epoch: 310 - Training loss: 0.0996 - Validation accuracy: 96.30%\n",
      "Epoch: 311 - Training loss: 0.0994 - Validation accuracy: 96.29%\n",
      "Epoch: 312 - Training loss: 0.0993 - Validation accuracy: 96.36%\n",
      "Epoch: 313 - Training loss: 0.0991 - Validation accuracy: 96.32%\n",
      "Epoch: 314 - Training loss: 0.0990 - Validation accuracy: 96.33%\n",
      "Epoch: 315 - Training loss: 0.0990 - Validation accuracy: 96.37%\n",
      "Epoch: 316 - Training loss: 0.0989 - Validation accuracy: 96.31%\n",
      "Epoch: 317 - Training loss: 0.0990 - Validation accuracy: 96.38%\n",
      "Epoch: 318 - Training loss: 0.0990 - Validation accuracy: 96.32%\n",
      "Epoch: 319 - Training loss: 0.0990 - Validation accuracy: 96.32%\n",
      "Epoch: 320 - Training loss: 0.0990 - Validation accuracy: 96.33%\n",
      "Epoch: 321 - Training loss: 0.0991 - Validation accuracy: 96.32%\n",
      "Epoch: 322 - Training loss: 0.0991 - Validation accuracy: 96.29%\n",
      "Epoch: 323 - Training loss: 0.0992 - Validation accuracy: 96.29%\n",
      "Epoch: 324 - Training loss: 0.0993 - Validation accuracy: 96.23%\n",
      "Epoch: 325 - Training loss: 0.0994 - Validation accuracy: 96.29%\n",
      "Epoch: 326 - Training loss: 0.0995 - Validation accuracy: 96.21%\n",
      "Epoch: 327 - Training loss: 0.0996 - Validation accuracy: 96.30%\n",
      "Epoch: 328 - Training loss: 0.0996 - Validation accuracy: 96.23%\n",
      "Epoch: 329 - Training loss: 0.0995 - Validation accuracy: 96.31%\n",
      "Epoch: 330 - Training loss: 0.0992 - Validation accuracy: 96.31%\n",
      "Epoch: 331 - Training loss: 0.0990 - Validation accuracy: 96.33%\n",
      "Epoch: 332 - Training loss: 0.0986 - Validation accuracy: 96.30%\n",
      "Epoch: 333 - Training loss: 0.0984 - Validation accuracy: 96.39%\n",
      "Epoch: 334 - Training loss: 0.0983 - Validation accuracy: 96.40%\n",
      "Epoch: 335 - Training loss: 0.0983 - Validation accuracy: 96.31%\n",
      "Epoch: 336 - Training loss: 0.0983 - Validation accuracy: 96.40%\n",
      "Epoch: 337 - Training loss: 0.0984 - Validation accuracy: 96.35%\n",
      "Epoch: 338 - Training loss: 0.0985 - Validation accuracy: 96.37%\n",
      "Epoch: 339 - Training loss: 0.0986 - Validation accuracy: 96.32%\n",
      "Epoch: 340 - Training loss: 0.0987 - Validation accuracy: 96.34%\n",
      "Epoch: 341 - Training loss: 0.0987 - Validation accuracy: 96.30%\n",
      "Epoch: 342 - Training loss: 0.0987 - Validation accuracy: 96.36%\n",
      "Epoch: 343 - Training loss: 0.0986 - Validation accuracy: 96.32%\n",
      "Epoch: 344 - Training loss: 0.0985 - Validation accuracy: 96.34%\n",
      "Epoch: 345 - Training loss: 0.0983 - Validation accuracy: 96.37%\n",
      "Epoch: 346 - Training loss: 0.0982 - Validation accuracy: 96.43%\n",
      "Epoch: 347 - Training loss: 0.0980 - Validation accuracy: 96.32%\n",
      "Epoch: 348 - Training loss: 0.0979 - Validation accuracy: 96.41%\n",
      "Epoch: 349 - Training loss: 0.0979 - Validation accuracy: 96.37%\n",
      "Epoch: 350 - Training loss: 0.0978 - Validation accuracy: 96.38%\n",
      "Epoch: 351 - Training loss: 0.0978 - Validation accuracy: 96.41%\n",
      "Epoch: 352 - Training loss: 0.0978 - Validation accuracy: 96.34%\n",
      "Epoch: 353 - Training loss: 0.0978 - Validation accuracy: 96.42%\n",
      "Epoch: 354 - Training loss: 0.0978 - Validation accuracy: 96.35%\n",
      "Epoch: 355 - Training loss: 0.0978 - Validation accuracy: 96.43%\n",
      "Epoch: 356 - Training loss: 0.0978 - Validation accuracy: 96.36%\n",
      "Epoch: 357 - Training loss: 0.0979 - Validation accuracy: 96.37%\n",
      "Epoch: 358 - Training loss: 0.0980 - Validation accuracy: 96.28%\n",
      "Epoch: 359 - Training loss: 0.0983 - Validation accuracy: 96.36%\n",
      "Epoch: 360 - Training loss: 0.0986 - Validation accuracy: 96.26%\n",
      "Epoch: 361 - Training loss: 0.0991 - Validation accuracy: 96.25%\n",
      "Epoch: 362 - Training loss: 0.0996 - Validation accuracy: 96.08%\n",
      "Epoch: 363 - Training loss: 0.1003 - Validation accuracy: 96.17%\n",
      "Epoch: 364 - Training loss: 0.1002 - Validation accuracy: 96.15%\n",
      "Epoch: 365 - Training loss: 0.0998 - Validation accuracy: 96.34%\n",
      "Epoch: 366 - Training loss: 0.0986 - Validation accuracy: 96.38%\n",
      "Epoch: 367 - Training loss: 0.0976 - Validation accuracy: 96.34%\n",
      "Epoch: 368 - Training loss: 0.0973 - Validation accuracy: 96.35%\n",
      "Epoch: 369 - Training loss: 0.0977 - Validation accuracy: 96.25%\n",
      "Epoch: 370 - Training loss: 0.0983 - Validation accuracy: 96.33%\n",
      "Epoch: 371 - Training loss: 0.0985 - Validation accuracy: 96.26%\n",
      "Epoch: 372 - Training loss: 0.0983 - Validation accuracy: 96.36%\n",
      "Epoch: 373 - Training loss: 0.0976 - Validation accuracy: 96.34%\n",
      "Epoch: 374 - Training loss: 0.0972 - Validation accuracy: 96.34%\n",
      "Epoch: 375 - Training loss: 0.0972 - Validation accuracy: 96.38%\n",
      "Epoch: 376 - Training loss: 0.0975 - Validation accuracy: 96.30%\n",
      "Epoch: 377 - Training loss: 0.0978 - Validation accuracy: 96.40%\n",
      "Epoch: 378 - Training loss: 0.0977 - Validation accuracy: 96.37%\n",
      "Epoch: 379 - Training loss: 0.0975 - Validation accuracy: 96.43%\n",
      "Epoch: 380 - Training loss: 0.0971 - Validation accuracy: 96.40%\n",
      "Epoch: 381 - Training loss: 0.0970 - Validation accuracy: 96.40%\n",
      "Epoch: 382 - Training loss: 0.0971 - Validation accuracy: 96.46%\n",
      "Epoch: 383 - Training loss: 0.0973 - Validation accuracy: 96.38%\n",
      "Epoch: 384 - Training loss: 0.0974 - Validation accuracy: 96.44%\n",
      "Epoch: 385 - Training loss: 0.0973 - Validation accuracy: 96.41%\n",
      "Epoch: 386 - Training loss: 0.0971 - Validation accuracy: 96.43%\n",
      "Epoch: 387 - Training loss: 0.0969 - Validation accuracy: 96.41%\n",
      "Epoch: 388 - Training loss: 0.0969 - Validation accuracy: 96.35%\n",
      "Epoch: 389 - Training loss: 0.0969 - Validation accuracy: 96.45%\n",
      "Epoch: 390 - Training loss: 0.0970 - Validation accuracy: 96.41%\n",
      "Epoch: 391 - Training loss: 0.0970 - Validation accuracy: 96.47%\n",
      "Epoch: 392 - Training loss: 0.0970 - Validation accuracy: 96.41%\n",
      "Epoch: 393 - Training loss: 0.0969 - Validation accuracy: 96.44%\n",
      "Epoch: 394 - Training loss: 0.0968 - Validation accuracy: 96.34%\n",
      "Epoch: 395 - Training loss: 0.0968 - Validation accuracy: 96.41%\n",
      "Epoch: 396 - Training loss: 0.0967 - Validation accuracy: 96.42%\n",
      "Epoch: 397 - Training loss: 0.0967 - Validation accuracy: 96.36%\n",
      "Epoch: 398 - Training loss: 0.0967 - Validation accuracy: 96.44%\n",
      "Epoch: 399 - Training loss: 0.0967 - Validation accuracy: 96.42%\n",
      "Epoch: 400 - Training loss: 0.0968 - Validation accuracy: 96.45%\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import Javascript  # Restrict height of output cell.\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 100})'''))\n",
    "\n",
    "model = GNNModel(HIDDEN_SIZE, NUM_LAYERS)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()\n",
    "      # We now give as input also the graph connectivity\n",
    "      #out = model(data.x, gso_index, gso_weight)\n",
    "      out = model(data.x, data.edge_index)\n",
    "      #print(len(out[data.train_mask]),len(data.y[data.train_mask]))\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      return loss\n",
    "\n",
    "def test(mask):\n",
    "      model.eval()\n",
    "      out = model(data.x, data.edge_index)\n",
    "      pred = out.argmax(dim=1)\n",
    "      test_correct = pred[mask] == data.y[mask]\n",
    "      test_acc = int(test_correct.sum()) / int(mask.sum())\n",
    "      test_out = out[mask]\n",
    "      test_pred = pred[mask]\n",
    "      return test_acc, test_out, test_pred\n",
    "\n",
    "for epoch in range(1, 401):\n",
    "    train_loss = train()\n",
    "    val_loss, _, _ = test(data.val_mask)\n",
    "    print(f'Epoch: {epoch:03d} - Training loss: {train_loss:.4f} - '\n",
    "          f'Validation accuracy: {val_loss * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 96.71%\n",
      "tensor([1, 1, 0,  ..., 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_out, test_pred  = test(data.test_mask)\n",
    "print(f'Test Accuracy: {test_acc * 100:.2f}%')\n",
    "print(test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(data.x, data.edge_index)\n",
    "#visualize(out, color=data.y)\n",
    "#visualize(out[data.test_mask], color=data.y[data.test_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9011973  0.9034956  0.00144282 ... 0.99960774 0.00369098 0.99960333]\n",
      "Precision: 0.94\n",
      "Recall: 0.96\n",
      "F1-score: 0.95\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support\n",
    "import torch.nn.functional as F\n",
    "\n",
    "y_true = data.y[data.test_mask]\n",
    "y_pred = softmax_x = F.softmax(test_out, dim=1)\n",
    "y_pred = y_pred[:, 1].detach().numpy()\n",
    "print(y_pred)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, test_pred, average='binary')\n",
    "\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))\n",
    "print(\"F1-score: {:.2f}\".format(f1_score))\n",
    "\n",
    "# Generate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16539\n",
      "16539\n",
      "0.9591689250225834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True,  ..., True, True, True])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data.y[data.test_mask]))\n",
    "print(len(y_pred))\n",
    "orig_test_y = data.y[data.test_mask]\n",
    "b = test_pred == orig_test_y\n",
    "c = b[orig_test_y == 1]\n",
    "print(np.sum(c.numpy()/len(c)))\n",
    "\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
