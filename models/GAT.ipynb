{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# Read in the CSV files\n",
    "\n",
    "# 0.1%\n",
    "#accounts_df = pd.read_csv(\"../datasets/p_0_1_percent/PS_20230505183351_53313/PS_20230505183351_53313_account_attributes.csv\")\n",
    "#transactions_df = pd.read_csv(\"../datasets/p_0_1_percent/PS_20230505183351_53313/PS_20230505183351_53313_rawLog.csv\")\n",
    "\n",
    "# 0.5%\n",
    "#accounts_df = pd.read_csv(\"../\")\n",
    "#transactions_df = pd.read_csv(\"../\")\n",
    "\n",
    "# 1%\n",
    "accounts_df = pd.read_csv(\"../datasets/p_1_percent/PS_20230509180228_53313/PS_20230509180228_53313_account_attributes.csv\")\n",
    "transactions_df = pd.read_csv(\"../datasets/p_1_percent/PS_20230509180228_53313/PS_20230509180228_53313_rawLog.csv\")\n",
    "\n",
    "# 5%\n",
    "#accounts_df = pd.read_csv(\"\")\n",
    "#transactions_df = pd.read_csv(\"\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>action</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <th>newBalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>isUnauthorizedOverdraft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>56.43</td>\n",
       "      <td>C7386126414</td>\n",
       "      <td>56.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC7215936899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>56.43</td>\n",
       "      <td>CC7215936899</td>\n",
       "      <td>56.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M7041720362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>30.16</td>\n",
       "      <td>C4388087190</td>\n",
       "      <td>30.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC5617012703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>30.16</td>\n",
       "      <td>CC5617012703</td>\n",
       "      <td>30.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M1980403693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>39.13</td>\n",
       "      <td>C0424020512</td>\n",
       "      <td>39.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC5817260722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step    action  amount      nameOrig  oldBalanceOrig  newBalanceOrig  \\\n",
       "0     0  TRANSFER   56.43   C7386126414           56.43             0.0   \n",
       "1     0  CASH_OUT   56.43  CC7215936899           56.43             0.0   \n",
       "2     0  TRANSFER   30.16   C4388087190           30.16             0.0   \n",
       "3     0  CASH_OUT   30.16  CC5617012703           30.16             0.0   \n",
       "4     0  TRANSFER   39.13   C0424020512           39.13             0.0   \n",
       "\n",
       "       nameDest  oldBalanceDest  newBalanceDest  isFraud  isFlaggedFraud  \\\n",
       "0  CC7215936899             0.0           56.43        1               0   \n",
       "1   M7041720362             0.0            0.00        1               0   \n",
       "2  CC5617012703             0.0           30.16        1               0   \n",
       "3   M1980403693             0.0            0.00        1               0   \n",
       "4  CC5817260722             0.0           39.13        1               0   \n",
       "\n",
       "   isUnauthorizedOverdraft  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df = accounts_df\n",
    "edges_df = transactions_df\n",
    "\n",
    "\n",
    "nodes_df.head()\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <th>newBalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>isUnauthorizedOverdraft</th>\n",
       "      <th>action_CASH_IN</th>\n",
       "      <th>action_CASH_OUT</th>\n",
       "      <th>action_DEBIT</th>\n",
       "      <th>action_PAYMENT</th>\n",
       "      <th>action_TRANSFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>56.43</td>\n",
       "      <td>C7386126414</td>\n",
       "      <td>56.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC7215936899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56.43</td>\n",
       "      <td>CC7215936899</td>\n",
       "      <td>56.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M7041720362</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>30.16</td>\n",
       "      <td>C4388087190</td>\n",
       "      <td>30.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC5617012703</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>30.16</td>\n",
       "      <td>CC5617012703</td>\n",
       "      <td>30.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M1980403693</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>39.13</td>\n",
       "      <td>C0424020512</td>\n",
       "      <td>39.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC5817260722</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step  amount      nameOrig  oldBalanceOrig  newBalanceOrig      nameDest  \\\n",
       "0     0   56.43   C7386126414           56.43             0.0  CC7215936899   \n",
       "1     0   56.43  CC7215936899           56.43             0.0   M7041720362   \n",
       "2     0   30.16   C4388087190           30.16             0.0  CC5617012703   \n",
       "3     0   30.16  CC5617012703           30.16             0.0   M1980403693   \n",
       "4     0   39.13   C0424020512           39.13             0.0  CC5817260722   \n",
       "\n",
       "   oldBalanceDest  newBalanceDest  isFraud  isFlaggedFraud  \\\n",
       "0             0.0           56.43        1               0   \n",
       "1             0.0            0.00        1               0   \n",
       "2             0.0           30.16        1               0   \n",
       "3             0.0            0.00        1               0   \n",
       "4             0.0           39.13        1               0   \n",
       "\n",
       "   isUnauthorizedOverdraft  action_CASH_IN  action_CASH_OUT  action_DEBIT  \\\n",
       "0                        0               0                0             0   \n",
       "1                        0               0                1             0   \n",
       "2                        0               0                0             0   \n",
       "3                        0               0                1             0   \n",
       "4                        0               0                0             0   \n",
       "\n",
       "   action_PAYMENT  action_TRANSFER  \n",
       "0               0                1  \n",
       "1               0                0  \n",
       "2               0                1  \n",
       "3               0                0  \n",
       "4               0                1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummies for the 'action' column\n",
    "dummies = pd.get_dummies(edges_df.action, prefix='action')\n",
    "\n",
    "# concatenate the dummies to the original DataFrame\n",
    "edges_df = pd.concat([edges_df, dummies], axis=1)\n",
    "\n",
    "# drop the original 'action' column\n",
    "edges_df.drop('action', axis=1, inplace=True)\n",
    "\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <th>newBalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>isUnauthorizedOverdraft</th>\n",
       "      <th>action_CASH_IN</th>\n",
       "      <th>action_CASH_OUT</th>\n",
       "      <th>action_DEBIT</th>\n",
       "      <th>action_PAYMENT</th>\n",
       "      <th>action_TRANSFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>56.43</td>\n",
       "      <td>56087</td>\n",
       "      <td>56.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15867</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.43</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>56.43</td>\n",
       "      <td>15867</td>\n",
       "      <td>56.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7113</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>30.16</td>\n",
       "      <td>28339</td>\n",
       "      <td>30.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40730</td>\n",
       "      <td>0.0</td>\n",
       "      <td>30.16</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>30.16</td>\n",
       "      <td>40730</td>\n",
       "      <td>30.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>39.13</td>\n",
       "      <td>52200</td>\n",
       "      <td>39.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44795</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.13</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step  amount  nameOrig  oldBalanceOrig  newBalanceOrig  nameDest  \\\n",
       "0     0   56.43     56087           56.43             0.0     15867   \n",
       "1     0   56.43     15867           56.43             0.0      7113   \n",
       "2     0   30.16     28339           30.16             0.0     40730   \n",
       "3     0   30.16     40730           30.16             0.0     41868   \n",
       "4     0   39.13     52200           39.13             0.0     44795   \n",
       "\n",
       "   oldBalanceDest  newBalanceDest  isFraud  isFlaggedFraud  \\\n",
       "0             0.0           56.43        1               0   \n",
       "1             0.0            0.00        1               0   \n",
       "2             0.0           30.16        1               0   \n",
       "3             0.0            0.00        1               0   \n",
       "4             0.0           39.13        1               0   \n",
       "\n",
       "   isUnauthorizedOverdraft  action_CASH_IN  action_CASH_OUT  action_DEBIT  \\\n",
       "0                        0               0                0             0   \n",
       "1                        0               0                1             0   \n",
       "2                        0               0                0             0   \n",
       "3                        0               0                1             0   \n",
       "4                        0               0                0             0   \n",
       "\n",
       "   action_PAYMENT  action_TRANSFER  \n",
       "0               0                1  \n",
       "1               0                0  \n",
       "2               0                1  \n",
       "3               0                0  \n",
       "4               0                1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we compute numerical indices for nameOrig and nameDest rather than their form 'CC6839167080'\n",
    "\n",
    "# Create a dictionary that maps each unique original name to a new unique ID\n",
    "node_ids = {node_name: i for i, node_name in enumerate(set(edges_df['nameOrig']).union(set(edges_df['nameDest'])))}\n",
    "\n",
    "\n",
    "# Replace the original names with the new IDs\n",
    "edges_df['nameOrig'] = edges_df['nameOrig'].map(node_ids)\n",
    "edges_df['nameDest'] = edges_df['nameDest'].map(node_ids)\n",
    "\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_deg_in</th>\n",
       "      <th>node_deg_out</th>\n",
       "      <th>node_deg_total</th>\n",
       "      <th>node_min_balance</th>\n",
       "      <th>node_max_balance</th>\n",
       "      <th>node_min_new_balance</th>\n",
       "      <th>node_max_new_balance</th>\n",
       "      <th>node_mean_new_balance</th>\n",
       "      <th>node_mean_old_balance</th>\n",
       "      <th>node_std_new_balance</th>\n",
       "      <th>...</th>\n",
       "      <th>node_actions_dependent_out_function_TRANSFER</th>\n",
       "      <th>node_actions_dependent_out_function_CASHIN</th>\n",
       "      <th>node_actions_dependent_out_function_CASHOUT</th>\n",
       "      <th>node_actions_dependent_out_function_DEBIT</th>\n",
       "      <th>node_actions_dependent_out_function_PAYMENT</th>\n",
       "      <th>node_countains_flagged_fraud</th>\n",
       "      <th>node_countains_unauth_overdraft</th>\n",
       "      <th>node_in_isFraud</th>\n",
       "      <th>node_out_isFraud</th>\n",
       "      <th>node_isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>547.0</td>\n",
       "      <td>3288124.73</td>\n",
       "      <td>7149951.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>330401.59</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>176571.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>85860.20</td>\n",
       "      <td>4046018.16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.997815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>5112756.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82687</th>\n",
       "      <td>9.0</td>\n",
       "      <td>295.0</td>\n",
       "      <td>304.0</td>\n",
       "      <td>701816.04</td>\n",
       "      <td>6542649.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.999970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82688</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>119243.94</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82689</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>224623.72</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82690</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3612411.19</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82691</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4801859.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82692 rows Ã— 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       node_deg_in  node_deg_out  node_deg_total  node_min_balance  \\\n",
       "0              7.0         540.0           547.0        3288124.73   \n",
       "1             94.0           0.0            94.0              0.00   \n",
       "2             95.0           0.0            95.0              0.00   \n",
       "3              5.0          34.0            39.0          85860.20   \n",
       "4              6.0           2.0             8.0              0.00   \n",
       "...            ...           ...             ...               ...   \n",
       "82687          9.0         295.0           304.0         701816.04   \n",
       "82688         81.0           0.0            81.0              0.00   \n",
       "82689         81.0           0.0            81.0              0.00   \n",
       "82690          5.0           2.0             7.0              0.00   \n",
       "82691          1.0           1.0             2.0              0.00   \n",
       "\n",
       "       node_max_balance  node_min_new_balance  node_max_new_balance  \\\n",
       "0            7149951.19                   0.0                   0.0   \n",
       "1             330401.59                   0.0                   0.0   \n",
       "2             176571.13                   0.0                   0.0   \n",
       "3            4046018.16                   0.0                   0.0   \n",
       "4            5112756.31                   0.0                   0.0   \n",
       "...                 ...                   ...                   ...   \n",
       "82687        6542649.96                   0.0                   0.0   \n",
       "82688         119243.94                   0.0                   0.0   \n",
       "82689         224623.72                   0.0                   0.0   \n",
       "82690        3612411.19                   0.0                   0.0   \n",
       "82691        4801859.06                   0.0                   0.0   \n",
       "\n",
       "       node_mean_new_balance  node_mean_old_balance  node_std_new_balance  \\\n",
       "0                        0.0                    0.0                   0.0   \n",
       "1                        0.0                    0.0                   0.0   \n",
       "2                        0.0                    0.0                   0.0   \n",
       "3                        0.0                    0.0                   0.0   \n",
       "4                        0.0                    0.0                   0.0   \n",
       "...                      ...                    ...                   ...   \n",
       "82687                    0.0                    0.0                   0.0   \n",
       "82688                    0.0                    0.0                   0.0   \n",
       "82689                    0.0                    0.0                   0.0   \n",
       "82690                    0.0                    0.0                   0.0   \n",
       "82691                    0.0                    0.0                   0.0   \n",
       "\n",
       "       ...  node_actions_dependent_out_function_TRANSFER  \\\n",
       "0      ...                                      0.999961   \n",
       "1      ...                                      0.000000   \n",
       "2      ...                                      0.000000   \n",
       "3      ...                                      0.997815   \n",
       "4      ...                                      0.000000   \n",
       "...    ...                                           ...   \n",
       "82687  ...                                      0.999970   \n",
       "82688  ...                                      0.000000   \n",
       "82689  ...                                      0.000000   \n",
       "82690  ...                                      0.000000   \n",
       "82691  ...                                      0.000000   \n",
       "\n",
       "       node_actions_dependent_out_function_CASHIN  \\\n",
       "0                                             0.0   \n",
       "1                                             0.0   \n",
       "2                                             0.0   \n",
       "3                                             0.0   \n",
       "4                                             0.0   \n",
       "...                                           ...   \n",
       "82687                                         0.0   \n",
       "82688                                         0.0   \n",
       "82689                                         0.0   \n",
       "82690                                         0.0   \n",
       "82691                                         0.0   \n",
       "\n",
       "       node_actions_dependent_out_function_CASHOUT  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "...                                            ...   \n",
       "82687                                          0.0   \n",
       "82688                                          0.0   \n",
       "82689                                          0.0   \n",
       "82690                                          0.0   \n",
       "82691                                          0.0   \n",
       "\n",
       "       node_actions_dependent_out_function_DEBIT  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "...                                          ...   \n",
       "82687                                        0.0   \n",
       "82688                                        0.0   \n",
       "82689                                        0.0   \n",
       "82690                                        0.0   \n",
       "82691                                        0.0   \n",
       "\n",
       "       node_actions_dependent_out_function_PAYMENT  \\\n",
       "0                                              0.0   \n",
       "1                                              0.0   \n",
       "2                                              0.0   \n",
       "3                                              0.0   \n",
       "4                                              0.0   \n",
       "...                                            ...   \n",
       "82687                                          0.0   \n",
       "82688                                          0.0   \n",
       "82689                                          0.0   \n",
       "82690                                          0.0   \n",
       "82691                                          0.0   \n",
       "\n",
       "       node_countains_flagged_fraud  node_countains_unauth_overdraft  \\\n",
       "0                               0.0                              0.0   \n",
       "1                               0.0                              1.0   \n",
       "2                               0.0                              0.0   \n",
       "3                               0.0                              0.0   \n",
       "4                               0.0                              0.0   \n",
       "...                             ...                              ...   \n",
       "82687                           0.0                              1.0   \n",
       "82688                           0.0                              1.0   \n",
       "82689                           0.0                              0.0   \n",
       "82690                           0.0                              0.0   \n",
       "82691                           0.0                              0.0   \n",
       "\n",
       "       node_in_isFraud  node_out_isFraud  node_isFraud  \n",
       "0                  0.0               1.0           0.0  \n",
       "1                  1.0               0.0           0.0  \n",
       "2                  0.0               0.0           0.0  \n",
       "3                  0.0               1.0           0.0  \n",
       "4                  1.0               1.0           1.0  \n",
       "...                ...               ...           ...  \n",
       "82687              0.0               0.0           0.0  \n",
       "82688              1.0               0.0           0.0  \n",
       "82689              1.0               0.0           0.0  \n",
       "82690              1.0               1.0           1.0  \n",
       "82691              1.0               1.0           1.0  \n",
       "\n",
       "[82692 rows x 44 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(61620, 41)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np = nodes_df.to_numpy()\n",
    "x = x_np[:,0:-3]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2, learning_rate='auto',\n",
    "             init='random').fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()\n",
    "\n",
    "def print_model_size(model):\n",
    "    tot = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "    out = f\"Number of model ({model.__class__.__name__}) parameters:{tot:10d}\"\n",
    "    print(\"=\" * len(out))\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "# Define your graph\n",
    "x = torch.nn.functional.normalize(torch.tensor(x),dim=0).to(torch.float32)  # (n x features)\n",
    "edge_index =  torch.stack([torch.tensor(edges_df.nameOrig.to_numpy()),torch.tensor(edges_df.nameDest.to_numpy())],dim=-1).T  # Define your edge index\n",
    "edge_attr = torch.nn.functional.normalize(torch.tensor(np.array(edges_df[['amount','oldBalanceOrig', 'newBalanceOrig', 'oldBalanceDest', 'newBalanceDest','isFlaggedFraud','isUnauthorizedOverdraft','action_CASH_IN','action_CASH_OUT','action_DEBIT','action_PAYMENT','action_TRANSFER']].values,dtype='float32')),dim=0) # edge features\n",
    "y =  torch.tensor(nodes_df.node_isFraud.to_numpy().astype(int)) # target values\n",
    "\n",
    "train_size = int(0.6 * len(y))  # 60% of the dataset for training\n",
    "val_size = int(0.2 * len(y))    # 20% of the dataset for validation\n",
    "test_size = len(y) - train_size - val_size  # Remaining 20% for testing\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(y, [train_size, val_size, test_size])\n",
    "\n",
    "# Create masks for train, validation, and test sets\n",
    "train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "val_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "\n",
    "train_mask[train_dataset.indices] = True\n",
    "val_mask[val_dataset.indices] = True\n",
    "test_mask[test_dataset.indices] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "# Load your data into PyTorch Geometric's Data class\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y,train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 61620\n",
      "Number of edges: 3797684\n",
      "Average node degree: 61.63\n",
      "==============================\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n",
      "Is weighted: False\n",
      "==============================\n",
      "Number of training nodes: 36972\n",
      "Training node label rate: 0.60\n"
     ]
    }
   ],
   "source": [
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "\n",
    "print('==============================')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "print(f'Is weighted: {data.edge_weight is not None}')\n",
    "\n",
    "print('==============================')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "def random_walk_matrix(edge_index, num_nodes: int = None):\n",
    "    source, target = edge_index[0], edge_index[1]\n",
    "    in_deg = degree(target, num_nodes=num_nodes)   # D\n",
    "    edge_weight = 1 / in_deg[target]               # D^-1 A\n",
    "    return edge_index, edge_weight\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edge weights: tensor([0.0769, 0.0115, 0.1250,  ..., 0.0128, 1.0000, 0.0125])\n",
      "tensor([[56087, 15867, 28339,  ..., 46111, 12486, 45199],\n",
      "        [15867,  7113, 40730,  ...,  4009, 45199,  3975]])\n"
     ]
    }
   ],
   "source": [
    "gso_index, gso_weight = random_walk_matrix(data.edge_index, data.num_nodes)\n",
    "print(f\"Edge weights: {gso_weight}\")\n",
    "print(gso_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNModel(\n",
      "  (convs): ModuleList(\n",
      "    (0): GATConv(41, 16, heads=1)\n",
      "    (1): GATConv(16, 16, heads=1)\n",
      "  )\n",
      "  (lin_out): Linear(in_features=16, out_features=2, bias=True)\n",
      ")\n",
      "================================================\n",
      "Number of model (GNNModel) parameters:      1042\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torch.nn import Linear, ReLU, Dropout\n",
    "from torch_geometric.nn import Sequential, GATConv\n",
    "\n",
    "HIDDEN_SIZE = 16 #@param\n",
    "NUM_LAYERS = 2 #@param\n",
    "\n",
    "dataset_num_node_features = x.size(1)\n",
    "dataset_num_edge_features = edge_attr.size(1)\n",
    "dataset_num_classes = 2\n",
    "\n",
    "class GNNModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size: int,\n",
    "                 num_layers: int = 1):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "\n",
    "        self.convs = torch.nn.ModuleList()\n",
    "        for l in range(num_layers):\n",
    "            #in_size = dataset_num_features if l == 0 else hidden_size\n",
    "            in_size = dataset_num_node_features if l == 0 else hidden_size\n",
    "            in_size2 = hidden_size + dataset_num_node_features + dataset_num_edge_features if l == 0 else hidden_size*2 + dataset_num_edge_features\n",
    "            conv = GATConv(in_channels=in_size, out_channels=hidden_size)\n",
    "            \n",
    "            #mpnn = MPNN(in_channels=in_size, out_channels=hidden_size, in_channels2=in_size2)\n",
    "            self.convs.append(conv)\n",
    "\n",
    "        self.lin_out = Linear(hidden_size, dataset_num_classes)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        # Message-passing: transform node features based on neighbors\n",
    "        relu = ReLU(inplace=True)\n",
    "        dropout = Dropout(p=0.2,inplace=True)\n",
    "        for conv in self.convs:\n",
    "            x = conv(x, edge_index)\n",
    "            #x = dropout(x)\n",
    "            x = relu(x)\n",
    "            #x = conv(x, edge_index, edge_attr=edge_attr)\n",
    "        # Decoder: post-process extracted features\n",
    "        out = self.lin_out(x)\n",
    "        return out\n",
    "\n",
    "model = GNNModel(HIDDEN_SIZE, NUM_LAYERS)\n",
    "print(model)\n",
    "print_model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import Sequential, GAT\n",
    "model = GAT(in_channels=dataset_num_node_features, hidden_channels=16, num_layers=3, out_channels=dataset_num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = GNNModel(HIDDEN_SIZE, NUM_LAYERS)\n",
    "model.eval()\n",
    "\n",
    "out = model(data.x, data.edge_index)\n",
    "#visualize(out, color=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "google.colab.output.setIframeHeight(0, true, {maxHeight: 100})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 - Training loss: 0.6927 - Validation accuracy: 88.83%\n",
      "Epoch: 002 - Training loss: 0.6692 - Validation accuracy: 88.83%\n",
      "Epoch: 003 - Training loss: 0.6433 - Validation accuracy: 88.83%\n",
      "Epoch: 004 - Training loss: 0.6163 - Validation accuracy: 88.83%\n",
      "Epoch: 005 - Training loss: 0.5879 - Validation accuracy: 88.83%\n",
      "Epoch: 006 - Training loss: 0.5582 - Validation accuracy: 88.83%\n",
      "Epoch: 007 - Training loss: 0.5279 - Validation accuracy: 88.83%\n",
      "Epoch: 008 - Training loss: 0.4975 - Validation accuracy: 88.83%\n",
      "Epoch: 009 - Training loss: 0.4677 - Validation accuracy: 88.83%\n",
      "Epoch: 010 - Training loss: 0.4394 - Validation accuracy: 88.83%\n",
      "Epoch: 011 - Training loss: 0.4134 - Validation accuracy: 88.83%\n",
      "Epoch: 012 - Training loss: 0.3908 - Validation accuracy: 88.83%\n",
      "Epoch: 013 - Training loss: 0.3723 - Validation accuracy: 88.83%\n",
      "Epoch: 014 - Training loss: 0.3587 - Validation accuracy: 88.83%\n",
      "Epoch: 015 - Training loss: 0.3504 - Validation accuracy: 88.83%\n",
      "Epoch: 016 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 017 - Training loss: 0.3483 - Validation accuracy: 88.83%\n",
      "Epoch: 018 - Training loss: 0.3526 - Validation accuracy: 88.83%\n",
      "Epoch: 019 - Training loss: 0.3584 - Validation accuracy: 88.83%\n",
      "Epoch: 020 - Training loss: 0.3642 - Validation accuracy: 88.83%\n",
      "Epoch: 021 - Training loss: 0.3686 - Validation accuracy: 88.83%\n",
      "Epoch: 022 - Training loss: 0.3712 - Validation accuracy: 88.83%\n",
      "Epoch: 023 - Training loss: 0.3716 - Validation accuracy: 88.83%\n",
      "Epoch: 024 - Training loss: 0.3703 - Validation accuracy: 88.83%\n",
      "Epoch: 025 - Training loss: 0.3674 - Validation accuracy: 88.83%\n",
      "Epoch: 026 - Training loss: 0.3637 - Validation accuracy: 88.83%\n",
      "Epoch: 027 - Training loss: 0.3596 - Validation accuracy: 88.83%\n",
      "Epoch: 028 - Training loss: 0.3557 - Validation accuracy: 88.83%\n",
      "Epoch: 029 - Training loss: 0.3523 - Validation accuracy: 88.83%\n",
      "Epoch: 030 - Training loss: 0.3496 - Validation accuracy: 88.83%\n",
      "Epoch: 031 - Training loss: 0.3479 - Validation accuracy: 88.83%\n",
      "Epoch: 032 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 033 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 034 - Training loss: 0.3478 - Validation accuracy: 88.83%\n",
      "Epoch: 035 - Training loss: 0.3488 - Validation accuracy: 88.83%\n",
      "Epoch: 036 - Training loss: 0.3498 - Validation accuracy: 88.83%\n",
      "Epoch: 037 - Training loss: 0.3507 - Validation accuracy: 88.83%\n",
      "Epoch: 038 - Training loss: 0.3512 - Validation accuracy: 88.83%\n",
      "Epoch: 039 - Training loss: 0.3513 - Validation accuracy: 88.83%\n",
      "Epoch: 040 - Training loss: 0.3511 - Validation accuracy: 88.83%\n",
      "Epoch: 041 - Training loss: 0.3507 - Validation accuracy: 88.83%\n",
      "Epoch: 042 - Training loss: 0.3500 - Validation accuracy: 88.83%\n",
      "Epoch: 043 - Training loss: 0.3493 - Validation accuracy: 88.83%\n",
      "Epoch: 044 - Training loss: 0.3486 - Validation accuracy: 88.83%\n",
      "Epoch: 045 - Training loss: 0.3480 - Validation accuracy: 88.83%\n",
      "Epoch: 046 - Training loss: 0.3475 - Validation accuracy: 88.83%\n",
      "Epoch: 047 - Training loss: 0.3472 - Validation accuracy: 88.83%\n",
      "Epoch: 048 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 049 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 050 - Training loss: 0.3472 - Validation accuracy: 88.83%\n",
      "Epoch: 051 - Training loss: 0.3474 - Validation accuracy: 88.83%\n",
      "Epoch: 052 - Training loss: 0.3476 - Validation accuracy: 88.83%\n",
      "Epoch: 053 - Training loss: 0.3476 - Validation accuracy: 88.83%\n",
      "Epoch: 054 - Training loss: 0.3476 - Validation accuracy: 88.83%\n",
      "Epoch: 055 - Training loss: 0.3475 - Validation accuracy: 88.83%\n",
      "Epoch: 056 - Training loss: 0.3474 - Validation accuracy: 88.83%\n",
      "Epoch: 057 - Training loss: 0.3473 - Validation accuracy: 88.83%\n",
      "Epoch: 058 - Training loss: 0.3472 - Validation accuracy: 88.83%\n",
      "Epoch: 059 - Training loss: 0.3472 - Validation accuracy: 88.83%\n",
      "Epoch: 060 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 061 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 062 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 063 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 064 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 065 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 066 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 067 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 068 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 069 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 070 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 071 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 072 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 073 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 074 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 075 - Training loss: 0.3471 - Validation accuracy: 88.83%\n",
      "Epoch: 076 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 077 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 078 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 079 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 080 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 081 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 082 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 083 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 084 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 085 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 086 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 087 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 088 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 089 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 090 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 091 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 092 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 093 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 094 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 095 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 096 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 097 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 098 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 099 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 100 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 101 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 102 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 103 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 104 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 105 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 106 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 107 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 108 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 109 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 110 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 111 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 112 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 113 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 114 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 115 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 116 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 117 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 118 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 119 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 120 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 121 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 122 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 123 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 124 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 125 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 126 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 127 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 128 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 129 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 130 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 131 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 132 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 133 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 134 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 135 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 136 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 137 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 138 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 139 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 140 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 141 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 142 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 143 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 144 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 145 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 146 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 147 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 148 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 149 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 150 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 151 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 152 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 153 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 154 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 155 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 156 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 157 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 158 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 159 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 160 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 161 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 162 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 163 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 164 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 165 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 166 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 167 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 168 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 169 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 170 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 171 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 172 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 173 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 174 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 175 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 176 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 177 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 178 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 179 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 180 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 181 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 182 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 183 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 184 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 185 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 186 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 187 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 188 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 189 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 190 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 191 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 192 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 193 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 194 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 195 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 196 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 197 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 198 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 199 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 200 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 201 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 202 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 203 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 204 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 205 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 206 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 207 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 208 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 209 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 210 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 211 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 212 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 213 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 214 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 215 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 216 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 217 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 218 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 219 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 220 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 221 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 222 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 223 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 224 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 225 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 226 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 227 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 228 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 229 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 230 - Training loss: 0.3470 - Validation accuracy: 88.83%\n",
      "Epoch: 231 - Training loss: 0.3470 - Validation accuracy: 88.83%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[39mreturn\u001b[39;00m test_acc, test_out, test_pred\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m401\u001b[39m):\n\u001b[0;32m---> 31\u001b[0m     train_loss \u001b[39m=\u001b[39m train()\n\u001b[1;32m     32\u001b[0m     val_loss, _, _ \u001b[39m=\u001b[39m test(data\u001b[39m.\u001b[39mval_mask)\n\u001b[1;32m     33\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m03d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m - Training loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     34\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation accuracy: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[21], line 16\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[39m#print(len(out[data.train_mask]),len(data.y[data.train_mask]))\u001b[39;00m\n\u001b[1;32m     15\u001b[0m loss \u001b[39m=\u001b[39m criterion(out[data\u001b[39m.\u001b[39mtrain_mask], data\u001b[39m.\u001b[39my[data\u001b[39m.\u001b[39mtrain_mask])\n\u001b[0;32m---> 16\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     17\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     18\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/anaconda3/envs/GDL/lib/python3.10/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/GDL/lib/python3.10/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import Javascript  # Restrict height of output cell.\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 100})'''))\n",
    "\n",
    "#model = GNNModel(HIDDEN_SIZE, NUM_LAYERS)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()\n",
    "      # We now give as input also the graph connectivity\n",
    "      #out = model(data.x, gso_index, gso_weight)\n",
    "      out = model(data.x, data.edge_index)\n",
    "      #print(len(out[data.train_mask]),len(data.y[data.train_mask]))\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      return loss\n",
    "\n",
    "def test(mask):\n",
    "      model.eval()\n",
    "      out = model(data.x, data.edge_index)\n",
    "      pred = out.argmax(dim=1)\n",
    "      test_correct = pred[mask] == data.y[mask]\n",
    "      test_acc = int(test_correct.sum()) / int(mask.sum())\n",
    "      test_out = out[mask]\n",
    "      test_pred = pred[mask]\n",
    "      return test_acc, test_out, test_pred\n",
    "\n",
    "for epoch in range(1, 401):\n",
    "    train_loss = train()\n",
    "    val_loss, _, _ = test(data.val_mask)\n",
    "    print(f'Epoch: {epoch:03d} - Training loss: {train_loss:.4f} - '\n",
    "          f'Validation accuracy: {val_loss * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 89.02%\n",
      "tensor([0, 0, 0,  ..., 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_out, test_pred  = test(data.test_mask)\n",
    "print(f'Test Accuracy: {test_acc * 100:.2f}%')\n",
    "print(test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(data.x, data.edge_index)\n",
    "#visualize(out, color=data.y)\n",
    "#visualize(out[data.test_mask], color=data.y[data.test_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.11057083 0.11056096 0.11055871 ... 0.11053981 0.11056205 0.11056077]\n",
      "Precision: 0.00\n",
      "Recall: 0.00\n",
      "F1-score: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julienschmidt/anaconda3/envs/GDL/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support\n",
    "import torch.nn.functional as F\n",
    "\n",
    "y_true = data.y[data.test_mask]\n",
    "y_pred = softmax_x = F.softmax(test_out, dim=1)\n",
    "y_pred = y_pred[:, 1].detach().numpy()\n",
    "print(y_pred)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, test_pred, average='binary')\n",
    "\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))\n",
    "print(\"F1-score: {:.2f}\".format(f1_score))\n",
    "\n",
    "# Generate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16539\n",
      "16539\n",
      "0.9591689250225834\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True,  ..., True, True, True])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data.y[data.test_mask]))\n",
    "print(len(y_pred))\n",
    "orig_test_y = data.y[data.test_mask]\n",
    "b = test_pred == orig_test_y\n",
    "c = b[orig_test_y == 1]\n",
    "print(np.sum(c.numpy()/len(c)))\n",
    "\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
