{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### TODO\n",
    "#\n",
    "# - clean the graph to simplify the problem\n",
    "#   - FORMAT 1\n",
    "#        - for nodes with multiple transactions between themselves, keep only one directed adge - remove all others. This edge will contain the number of transactions and the average amount of those transactions\n",
    "#\n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "# 0.1%\n",
    "#accounts_df = pd.read_csv(\"../datasets/p_0_1_percent/PS_20230428161042_1211346587/PS_20230428161042_1211346587_account_attributes.csv\")\n",
    "#transactions_df = pd.read_csv(\"../datasets/p_0_1_percent/PS_20230428161042_1211346587/PS_20230428161042_1211346587_rawLog.csv\")\n",
    "\n",
    "# 1%\n",
    "#accounts_df = pd.read_csv(\"../datasets/p_1_percent/PS_20230504121043_87775/PS_20230504121043_87775_account_attributes.csv\")\n",
    "#transactions_df = pd.read_csv(\"../datasets/p_1_percent/PS_20230504121043_87775/PS_20230504121043_87775_rawLog.csv\")\n",
    "\n",
    "# 5%\n",
    "accounts_df = pd.read_csv(\"../datasets/p_5_percent/PS_20230504134819_26105/PS_20230504134819_26105_account_attributes.csv\")\n",
    "transactions_df = pd.read_csv(\"../datasets/p_5_percent/PS_20230504134819_26105/PS_20230504134819_26105_rawLog.csv\")\n",
    "\n",
    "# 10%\n",
    "#accounts_df = pd.read_csv(\"\")\n",
    "#transactions_df = pd.read_csv(\"\")\n",
    "\n",
    "# 20%\n",
    "#accounts_df = pd.read_csv(\"\")\n",
    "#transactions_df = pd.read_csv(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>action</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <th>newBalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>isUnauthorizedOverdraft</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>94.57</td>\n",
       "      <td>C5393210639</td>\n",
       "      <td>94.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC7736975753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>94.57</td>\n",
       "      <td>CC7736975753</td>\n",
       "      <td>94.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M2927363590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>84.47</td>\n",
       "      <td>C2070951585</td>\n",
       "      <td>84.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC3218672791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>CASH_OUT</td>\n",
       "      <td>84.47</td>\n",
       "      <td>CC3218672791</td>\n",
       "      <td>84.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M3968125771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>TRANSFER</td>\n",
       "      <td>91.27</td>\n",
       "      <td>C3284385768</td>\n",
       "      <td>91.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC3328636106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step    action  amount      nameOrig  oldBalanceOrig  newBalanceOrig  \\\n",
       "0     0  TRANSFER   94.57   C5393210639           94.57             0.0   \n",
       "1     0  CASH_OUT   94.57  CC7736975753           94.57             0.0   \n",
       "2     0  TRANSFER   84.47   C2070951585           84.47             0.0   \n",
       "3     0  CASH_OUT   84.47  CC3218672791           84.47             0.0   \n",
       "4     0  TRANSFER   91.27   C3284385768           91.27             0.0   \n",
       "\n",
       "       nameDest  oldBalanceDest  newBalanceDest  isFraud  isFlaggedFraud  \\\n",
       "0  CC7736975753             0.0           94.57        1               0   \n",
       "1   M2927363590             0.0            0.00        1               0   \n",
       "2  CC3218672791             0.0           84.47        1               0   \n",
       "3   M3968125771             0.0            0.00        1               0   \n",
       "4  CC3328636106             0.0           91.27        1               0   \n",
       "\n",
       "   isUnauthorizedOverdraft  \n",
       "0                        0  \n",
       "1                        0  \n",
       "2                        0  \n",
       "3                        0  \n",
       "4                        0  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df = accounts_df\n",
    "edges_df = transactions_df\n",
    "\n",
    "\n",
    "nodes_df.head()\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <th>newBalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>isUnauthorizedOverdraft</th>\n",
       "      <th>action_CASH_IN</th>\n",
       "      <th>action_CASH_OUT</th>\n",
       "      <th>action_DEBIT</th>\n",
       "      <th>action_PAYMENT</th>\n",
       "      <th>action_TRANSFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>94.57</td>\n",
       "      <td>C5393210639</td>\n",
       "      <td>94.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC7736975753</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>94.57</td>\n",
       "      <td>CC7736975753</td>\n",
       "      <td>94.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M2927363590</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>84.47</td>\n",
       "      <td>C2070951585</td>\n",
       "      <td>84.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC3218672791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>84.47</td>\n",
       "      <td>CC3218672791</td>\n",
       "      <td>84.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>M3968125771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>91.27</td>\n",
       "      <td>C3284385768</td>\n",
       "      <td>91.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CC3328636106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step  amount      nameOrig  oldBalanceOrig  newBalanceOrig      nameDest  \\\n",
       "0     0   94.57   C5393210639           94.57             0.0  CC7736975753   \n",
       "1     0   94.57  CC7736975753           94.57             0.0   M2927363590   \n",
       "2     0   84.47   C2070951585           84.47             0.0  CC3218672791   \n",
       "3     0   84.47  CC3218672791           84.47             0.0   M3968125771   \n",
       "4     0   91.27   C3284385768           91.27             0.0  CC3328636106   \n",
       "\n",
       "   oldBalanceDest  newBalanceDest  isFraud  isFlaggedFraud  \\\n",
       "0             0.0           94.57        1               0   \n",
       "1             0.0            0.00        1               0   \n",
       "2             0.0           84.47        1               0   \n",
       "3             0.0            0.00        1               0   \n",
       "4             0.0           91.27        1               0   \n",
       "\n",
       "   isUnauthorizedOverdraft  action_CASH_IN  action_CASH_OUT  action_DEBIT  \\\n",
       "0                        0               0                0             0   \n",
       "1                        0               0                1             0   \n",
       "2                        0               0                0             0   \n",
       "3                        0               0                1             0   \n",
       "4                        0               0                0             0   \n",
       "\n",
       "   action_PAYMENT  action_TRANSFER  \n",
       "0               0                1  \n",
       "1               0                0  \n",
       "2               0                1  \n",
       "3               0                0  \n",
       "4               0                1  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create dummies for the 'action' column\n",
    "dummies = pd.get_dummies(edges_df.action, prefix='action')\n",
    "\n",
    "# concatenate the dummies to the original DataFrame\n",
    "edges_df = pd.concat([edges_df, dummies], axis=1)\n",
    "\n",
    "# drop the original 'action' column\n",
    "edges_df.drop('action', axis=1, inplace=True)\n",
    "\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>step</th>\n",
       "      <th>amount</th>\n",
       "      <th>nameOrig</th>\n",
       "      <th>oldBalanceOrig</th>\n",
       "      <th>newBalanceOrig</th>\n",
       "      <th>nameDest</th>\n",
       "      <th>oldBalanceDest</th>\n",
       "      <th>newBalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "      <th>isFlaggedFraud</th>\n",
       "      <th>isUnauthorizedOverdraft</th>\n",
       "      <th>action_CASH_IN</th>\n",
       "      <th>action_CASH_OUT</th>\n",
       "      <th>action_DEBIT</th>\n",
       "      <th>action_PAYMENT</th>\n",
       "      <th>action_TRANSFER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>94.57</td>\n",
       "      <td>74371</td>\n",
       "      <td>94.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>59086</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.57</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>94.57</td>\n",
       "      <td>59086</td>\n",
       "      <td>94.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25033</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>84.47</td>\n",
       "      <td>21116</td>\n",
       "      <td>84.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71147</td>\n",
       "      <td>0.0</td>\n",
       "      <td>84.47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>84.47</td>\n",
       "      <td>71147</td>\n",
       "      <td>84.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46068</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>91.27</td>\n",
       "      <td>38372</td>\n",
       "      <td>91.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>74648</td>\n",
       "      <td>0.0</td>\n",
       "      <td>91.27</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   step  amount  nameOrig  oldBalanceOrig  newBalanceOrig  nameDest  \\\n",
       "0     0   94.57     74371           94.57             0.0     59086   \n",
       "1     0   94.57     59086           94.57             0.0     25033   \n",
       "2     0   84.47     21116           84.47             0.0     71147   \n",
       "3     0   84.47     71147           84.47             0.0     46068   \n",
       "4     0   91.27     38372           91.27             0.0     74648   \n",
       "\n",
       "   oldBalanceDest  newBalanceDest  isFraud  isFlaggedFraud  \\\n",
       "0             0.0           94.57        1               0   \n",
       "1             0.0            0.00        1               0   \n",
       "2             0.0           84.47        1               0   \n",
       "3             0.0            0.00        1               0   \n",
       "4             0.0           91.27        1               0   \n",
       "\n",
       "   isUnauthorizedOverdraft  action_CASH_IN  action_CASH_OUT  action_DEBIT  \\\n",
       "0                        0               0                0             0   \n",
       "1                        0               0                1             0   \n",
       "2                        0               0                0             0   \n",
       "3                        0               0                1             0   \n",
       "4                        0               0                0             0   \n",
       "\n",
       "   action_PAYMENT  action_TRANSFER  \n",
       "0               0                1  \n",
       "1               0                0  \n",
       "2               0                1  \n",
       "3               0                0  \n",
       "4               0                1  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we compute numerical indices for nameOrig and nameDest rather than their form 'CC6839167080'\n",
    "\n",
    "# Create a dictionary that maps each unique original name to a new unique ID\n",
    "node_ids = {node_name: i for i, node_name in enumerate(set(edges_df['nameOrig']).union(set(edges_df['nameDest'])))}\n",
    "\n",
    "\n",
    "# Replace the original names with the new IDs\n",
    "edges_df['nameOrig'] = edges_df['nameOrig'].map(node_ids)\n",
    "edges_df['nameDest'] = edges_df['nameDest'].map(node_ids)\n",
    "\n",
    "edges_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_deg_in</th>\n",
       "      <th>node_deg_out</th>\n",
       "      <th>node_deg_total</th>\n",
       "      <th>node_min_balance</th>\n",
       "      <th>node_max_balance</th>\n",
       "      <th>node_min_new_balance</th>\n",
       "      <th>node_max_new_balance</th>\n",
       "      <th>node_mean_new_balance</th>\n",
       "      <th>node_mean_old_balance</th>\n",
       "      <th>node_std_new_balance</th>\n",
       "      <th>...</th>\n",
       "      <th>node_actions_dependent_out_function_TRANSFER</th>\n",
       "      <th>node_actions_dependent_out_function_CASHIN</th>\n",
       "      <th>node_actions_dependent_out_function_CASHOUT</th>\n",
       "      <th>node_actions_dependent_out_function_DEBIT</th>\n",
       "      <th>node_actions_dependent_out_function_PAYMENT</th>\n",
       "      <th>node_countains_flagged_fraud</th>\n",
       "      <th>node_countains_unauth_overdraft</th>\n",
       "      <th>node_in_isFraud</th>\n",
       "      <th>node_out_isFraud</th>\n",
       "      <th>node_isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1480381.27</td>\n",
       "      <td>5235731.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>134403.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>79.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>182519.38</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>250806.46</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>82.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>166623.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_deg_in  node_deg_out  node_deg_total  node_min_balance  \\\n",
       "0         12.0         135.0           147.0        1480381.27   \n",
       "1         83.0           0.0            83.0              0.00   \n",
       "2         79.0           0.0            79.0              0.00   \n",
       "3        102.0           0.0           102.0              0.00   \n",
       "4         82.0           0.0            82.0              0.00   \n",
       "\n",
       "   node_max_balance  node_min_new_balance  node_max_new_balance  \\\n",
       "0        5235731.87                   0.0                   0.0   \n",
       "1         134403.47                   0.0                   0.0   \n",
       "2         182519.38                   0.0                   0.0   \n",
       "3         250806.46                   0.0                   0.0   \n",
       "4         166623.68                   0.0                   0.0   \n",
       "\n",
       "   node_mean_new_balance  node_mean_old_balance  node_std_new_balance  ...  \\\n",
       "0                    0.0                    0.0                   0.0  ...   \n",
       "1                    0.0                    0.0                   0.0  ...   \n",
       "2                    0.0                    0.0                   0.0  ...   \n",
       "3                    0.0                    0.0                   0.0  ...   \n",
       "4                    0.0                    0.0                   0.0  ...   \n",
       "\n",
       "   node_actions_dependent_out_function_TRANSFER  \\\n",
       "0                                           1.0   \n",
       "1                                           0.0   \n",
       "2                                           0.0   \n",
       "3                                           0.0   \n",
       "4                                           0.0   \n",
       "\n",
       "   node_actions_dependent_out_function_CASHIN  \\\n",
       "0                                         0.0   \n",
       "1                                         0.0   \n",
       "2                                         0.0   \n",
       "3                                         0.0   \n",
       "4                                         0.0   \n",
       "\n",
       "   node_actions_dependent_out_function_CASHOUT  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   node_actions_dependent_out_function_DEBIT  \\\n",
       "0                                        0.0   \n",
       "1                                        0.0   \n",
       "2                                        0.0   \n",
       "3                                        0.0   \n",
       "4                                        0.0   \n",
       "\n",
       "   node_actions_dependent_out_function_PAYMENT  node_countains_flagged_fraud  \\\n",
       "0                                          0.0                           0.0   \n",
       "1                                          0.0                           0.0   \n",
       "2                                          0.0                           0.0   \n",
       "3                                          0.0                           0.0   \n",
       "4                                          0.0                           0.0   \n",
       "\n",
       "   node_countains_unauth_overdraft  node_in_isFraud  node_out_isFraud  \\\n",
       "0                              0.0              0.0               0.0   \n",
       "1                              0.0              0.0               0.0   \n",
       "2                              0.0              0.0               0.0   \n",
       "3                              0.0              0.0               0.0   \n",
       "4                              0.0              0.0               0.0   \n",
       "\n",
       "   node_isFraud  \n",
       "0           0.0  \n",
       "1           0.0  \n",
       "2           0.0  \n",
       "3           0.0  \n",
       "4           0.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(82692, 41)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_np = nodes_df.to_numpy()\n",
    "x = x_np[:,0:-3]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "# Helper function for visualization.\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from torch_geometric.transforms import NormalizeFeatures\n",
    "\n",
    "def visualize(h, color):\n",
    "    z = TSNE(n_components=2, learning_rate='auto',\n",
    "             init='random').fit_transform(h.detach().cpu().numpy())\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.scatter(z[:, 0], z[:, 1], s=70, c=color, cmap=\"Set2\")\n",
    "    plt.show()\n",
    "\n",
    "def print_model_size(model):\n",
    "    tot = sum([p.numel() for p in model.parameters() if p.requires_grad])\n",
    "    out = f\"Number of model ({model.__class__.__name__}) parameters:{tot:10d}\"\n",
    "    print(\"=\" * len(out))\n",
    "    print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "# Define your graph\n",
    "x = torch.nn.functional.normalize(torch.tensor(x),dim=0).to(torch.float32)  # (n x features)\n",
    "edge_index =  torch.stack([torch.tensor(edges_df.nameOrig.to_numpy()),torch.tensor(edges_df.nameDest.to_numpy())],dim=-1).T  # Define your edge index\n",
    "edge_attr = torch.nn.functional.normalize(torch.tensor(np.array(edges_df[['amount','oldBalanceOrig', 'newBalanceOrig', 'oldBalanceDest', 'newBalanceDest','isFlaggedFraud','isUnauthorizedOverdraft','action_CASH_IN','action_CASH_OUT','action_DEBIT','action_PAYMENT','action_TRANSFER']].values,dtype='float32')),dim=0) # edge features\n",
    "y =  torch.tensor(nodes_df.node_isFraud.to_numpy().astype(int)) # target values\n",
    "\n",
    "train_size = int(0.6 * len(y))  # 60% of the dataset for training\n",
    "val_size = int(0.2 * len(y))    # 20% of the dataset for validation\n",
    "test_size = len(y) - train_size - val_size  # Remaining 20% for testing\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(y, [train_size, val_size, test_size])\n",
    "\n",
    "# Create masks for train, validation, and test sets\n",
    "train_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "val_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "test_mask = torch.zeros(len(y), dtype=torch.bool)\n",
    "\n",
    "train_mask[train_dataset.indices] = True\n",
    "val_mask[val_dataset.indices] = True\n",
    "test_mask[test_dataset.indices] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "# Load your data into PyTorch Geometric's Data class\n",
    "data = Data(x=x, edge_index=edge_index, edge_attr=edge_attr, y=y,train_mask=train_mask, val_mask=val_mask, test_mask=test_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 82692\n",
      "Number of edges: 3491520\n",
      "Average node degree: 42.22\n",
      "==============================\n",
      "Has isolated nodes: False\n",
      "Has self-loops: False\n",
      "Is undirected: False\n",
      "Is weighted: False\n",
      "==============================\n",
      "Number of training nodes: 49615\n",
      "Training node label rate: 0.60\n"
     ]
    }
   ],
   "source": [
    "# Gather some statistics about the graph.\n",
    "print(f'Number of nodes: {data.num_nodes}')\n",
    "print(f'Number of edges: {data.num_edges}')\n",
    "print(f'Average node degree: {data.num_edges / data.num_nodes:.2f}')\n",
    "\n",
    "print('==============================')\n",
    "print(f'Has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Has self-loops: {data.has_self_loops()}')\n",
    "print(f'Is undirected: {data.is_undirected()}')\n",
    "print(f'Is weighted: {data.edge_weight is not None}')\n",
    "\n",
    "print('==============================')\n",
    "print(f'Number of training nodes: {data.train_mask.sum()}')\n",
    "print(f'Training node label rate: {int(data.train_mask.sum()) / data.num_nodes:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from torch.nn import Linear\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import degree\n",
    "\n",
    "def random_walk_matrix(edge_index, num_nodes: int = None):\n",
    "    source, target = edge_index[0], edge_index[1]\n",
    "    in_deg = degree(target, num_nodes=num_nodes)   # D\n",
    "    edge_weight = 1 / in_deg[target]               # D^-1 A\n",
    "    return edge_index, edge_weight\n",
    "\n",
    "\n",
    "class MPNN(MessagePassing):\n",
    "    def __init__(self, in_channels: int, out_channels: int, in_channels2: int):\n",
    "        super().__init__(aggr=\"add\")                         # \"sum\" aggregation\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.lin_message = Linear(in_channels, out_channels, # weights 𝚯_1\n",
    "                                  bias=False)\n",
    "        self.lin_update = Linear(in_channels2, out_channels,  # weights 𝚯_2\n",
    "                                 bias=True)                  # the bias vector 𝐛\n",
    "        \n",
    "        self.lin1 = Linear(in_channels, out_channels)\n",
    "        self.lin2 = Linear(out_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        # x has shape [N, in_channels]\n",
    "        # edge_index has shape [2, E]\n",
    "        # edge_attr has shape [E, edge_dim]\n",
    "        #print('x', x.size())\n",
    "        #print('edge_index', edge_index.size())\n",
    "        #print('edge_attr', edge_attr.size())\n",
    "\n",
    "        if edge_attr is None:\n",
    "            edge_attr = torch.ones((edge_index.size(1), 1), device=x.device)\n",
    "        # 1. m_j→𝑖 = x_j𝚯_1\n",
    "        m_ji = self.lin_message(x)  # we can project here with isotropic GNNs\n",
    "        #m_ji = x  # I decided since we only have one feature, it doesnt make sense to apply a linear to dim 16\n",
    "        # 2. m_𝑖 = add(ã_ji ⋅ m_j→𝑖)_j∈𝑁(i)\n",
    "        #print('mji', m_ji.size())\n",
    "        m_i = self.propagate(edge_index, m=m_ji, edge_attr=edge_attr)\n",
    "        # 3. h_𝑖 = tanh(x_i𝚯_2 + m_i + 𝐛)\n",
    "        #print('mi', m_i.size())\n",
    "        #h_i = torch.tanh(self.lin_update(x) + m_i)\n",
    "        a = torch.cat([x, m_i], dim=-1)\n",
    "        #print('ehh')\n",
    "        #print('here', a.size())\n",
    "        #print('ehh2')\n",
    "        \n",
    "        #print()\n",
    "        #print('here2', self.lin_update(a).size())\n",
    "        h_i = torch.tanh(self.lin_update(a))\n",
    "        return h_i\n",
    "\n",
    "    def message(self, m_j, edge_attr):\n",
    "        # x_j has shape [E, in_channels]\n",
    "        # edge_attr has shape [E, edge_dim]\n",
    "\n",
    "        #print(m_j)\n",
    "        #print(m_j.size())\n",
    "        #print(edge_attr.size())\n",
    "        #return edge_attr.reshape(-1, 1) * m_j\n",
    "        #return edge_attr.view(-1, 1) * m_j\n",
    "        return torch.cat([m_j, edge_attr], dim=-1)\n",
    "        \n",
    "        #The code return edge_attr.view(-1, 1) * x_j multiplies the input message x_j with the edge attributes edge_attr.\n",
    "        #Here, x_j represents the message passed from the node j to its neighbor node i, and edge_attr represents the corresponding edge attribute associated with the edge connecting the nodes i and j.\n",
    "        #The view(-1, 1) method call is used to reshape edge_attr to have one column and as many rows as there are messages passed between nodes. This is done so that the multiplication operation between x_j and edge_attr can be performed element-wise between the corresponding rows of x_j and edge_attr.\n",
    "        #The resulting tensor has the same shape as x_j and represents the transformed messages to be aggregated by the receiving node i.\n",
    "\n",
    "#    def message(self, m_j, edge_weight):\n",
    "#        return edge_weight.view(-1, 1) * m_j  # ã_ji ⋅ m_j→𝑖\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GNNModel(\n",
      "  (mpnns): ModuleList(\n",
      "    (0): MPNN(41, 16)\n",
      "    (1): MPNN(16, 16)\n",
      "  )\n",
      "  (lin_out): Linear(in_features=16, out_features=2, bias=True)\n",
      ")\n",
      "================================================\n",
      "Number of model (GNNModel) parameters:      4274\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "from torch.nn import Linear\n",
    "\n",
    "HIDDEN_SIZE = 16 #@param\n",
    "NUM_LAYERS = 2 #@param\n",
    "\n",
    "dataset_num_node_features = x.size(1)\n",
    "dataset_num_edge_features = edge_attr.size(1)\n",
    "dataset_num_classes = 2\n",
    "\n",
    "class GNNModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, hidden_size: int,\n",
    "                 num_layers: int = 1):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "\n",
    "        self.mpnns = torch.nn.ModuleList()\n",
    "        for l in range(num_layers):\n",
    "            #in_size = dataset_num_features if l == 0 else hidden_size\n",
    "            in_size = dataset_num_node_features if l == 0 else hidden_size\n",
    "            in_size2 = hidden_size + dataset_num_node_features + dataset_num_edge_features if l == 0 else hidden_size*2 + dataset_num_edge_features\n",
    "            mpnn = MPNN(in_channels=in_size, out_channels=hidden_size, in_channels2=in_size2)\n",
    "            self.mpnns.append(mpnn)\n",
    "\n",
    "        self.lin_out = Linear(hidden_size, dataset_num_classes)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        # Message-passing: transform node features based on neighbors\n",
    "        for mpnn in self.mpnns:\n",
    "            #x = mpnn(x, edge_index, edge_weight)\n",
    "            x = mpnn(x, edge_index, edge_attr=edge_attr)\n",
    "        # Decoder: post-process extracted features\n",
    "        out = self.lin_out(x)\n",
    "        return out\n",
    "\n",
    "model = GNNModel(HIDDEN_SIZE, NUM_LAYERS)\n",
    "print(model)\n",
    "print_model_size(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GNNModel(HIDDEN_SIZE, NUM_LAYERS)\n",
    "model.eval()\n",
    "\n",
    "out = model(data.x, data.edge_index, edge_attr=data.edge_attr)\n",
    "#visualize(out, color=data.y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": "google.colab.output.setIframeHeight(0, true, {maxHeight: 100})",
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001 - Training loss: 0.7890 - Validation accuracy: 47.46%\n",
      "Epoch: 002 - Training loss: 0.7031 - Validation accuracy: 51.84%\n",
      "Epoch: 003 - Training loss: 0.6970 - Validation accuracy: 55.67%\n",
      "Epoch: 004 - Training loss: 0.6855 - Validation accuracy: 58.78%\n",
      "Epoch: 005 - Training loss: 0.6734 - Validation accuracy: 60.39%\n",
      "Epoch: 006 - Training loss: 0.6638 - Validation accuracy: 60.38%\n",
      "Epoch: 007 - Training loss: 0.6570 - Validation accuracy: 66.03%\n",
      "Epoch: 008 - Training loss: 0.6522 - Validation accuracy: 66.02%\n",
      "Epoch: 009 - Training loss: 0.6483 - Validation accuracy: 66.02%\n",
      "Epoch: 010 - Training loss: 0.6452 - Validation accuracy: 66.02%\n",
      "Epoch: 011 - Training loss: 0.6429 - Validation accuracy: 66.02%\n",
      "Epoch: 012 - Training loss: 0.6414 - Validation accuracy: 66.02%\n",
      "Epoch: 013 - Training loss: 0.6408 - Validation accuracy: 66.02%\n",
      "Epoch: 014 - Training loss: 0.6408 - Validation accuracy: 66.02%\n",
      "Epoch: 015 - Training loss: 0.6409 - Validation accuracy: 66.02%\n",
      "Epoch: 016 - Training loss: 0.6407 - Validation accuracy: 66.02%\n",
      "Epoch: 017 - Training loss: 0.6404 - Validation accuracy: 66.02%\n",
      "Epoch: 018 - Training loss: 0.6399 - Validation accuracy: 66.02%\n",
      "Epoch: 019 - Training loss: 0.6392 - Validation accuracy: 66.02%\n",
      "Epoch: 020 - Training loss: 0.6388 - Validation accuracy: 66.02%\n",
      "Epoch: 021 - Training loss: 0.6387 - Validation accuracy: 66.02%\n",
      "Epoch: 022 - Training loss: 0.6385 - Validation accuracy: 66.02%\n",
      "Epoch: 023 - Training loss: 0.6383 - Validation accuracy: 66.02%\n",
      "Epoch: 024 - Training loss: 0.6380 - Validation accuracy: 66.02%\n",
      "Epoch: 025 - Training loss: 0.6378 - Validation accuracy: 66.02%\n",
      "Epoch: 026 - Training loss: 0.6378 - Validation accuracy: 66.02%\n",
      "Epoch: 027 - Training loss: 0.6379 - Validation accuracy: 66.02%\n",
      "Epoch: 028 - Training loss: 0.6378 - Validation accuracy: 66.02%\n",
      "Epoch: 029 - Training loss: 0.6377 - Validation accuracy: 66.02%\n",
      "Epoch: 030 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 031 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 032 - Training loss: 0.6377 - Validation accuracy: 66.02%\n",
      "Epoch: 033 - Training loss: 0.6377 - Validation accuracy: 66.02%\n",
      "Epoch: 034 - Training loss: 0.6377 - Validation accuracy: 66.02%\n",
      "Epoch: 035 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 036 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 037 - Training loss: 0.6377 - Validation accuracy: 66.02%\n",
      "Epoch: 038 - Training loss: 0.6377 - Validation accuracy: 66.02%\n",
      "Epoch: 039 - Training loss: 0.6377 - Validation accuracy: 66.02%\n",
      "Epoch: 040 - Training loss: 0.6377 - Validation accuracy: 66.02%\n",
      "Epoch: 041 - Training loss: 0.6377 - Validation accuracy: 66.02%\n",
      "Epoch: 042 - Training loss: 0.6377 - Validation accuracy: 66.02%\n",
      "Epoch: 043 - Training loss: 0.6377 - Validation accuracy: 66.02%\n",
      "Epoch: 044 - Training loss: 0.6377 - Validation accuracy: 66.02%\n",
      "Epoch: 045 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 046 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 047 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 048 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 049 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 050 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 051 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 052 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 053 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 054 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 055 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 056 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 057 - Training loss: 0.6376 - Validation accuracy: 66.02%\n",
      "Epoch: 058 - Training loss: 0.6375 - Validation accuracy: 66.02%\n",
      "Epoch: 059 - Training loss: 0.6375 - Validation accuracy: 66.02%\n",
      "Epoch: 060 - Training loss: 0.6375 - Validation accuracy: 66.02%\n",
      "Epoch: 061 - Training loss: 0.6375 - Validation accuracy: 66.02%\n",
      "Epoch: 062 - Training loss: 0.6375 - Validation accuracy: 66.02%\n",
      "Epoch: 063 - Training loss: 0.6375 - Validation accuracy: 66.02%\n",
      "Epoch: 064 - Training loss: 0.6375 - Validation accuracy: 66.02%\n",
      "Epoch: 065 - Training loss: 0.6375 - Validation accuracy: 66.02%\n",
      "Epoch: 066 - Training loss: 0.6375 - Validation accuracy: 66.02%\n",
      "Epoch: 067 - Training loss: 0.6375 - Validation accuracy: 66.02%\n",
      "Epoch: 068 - Training loss: 0.6374 - Validation accuracy: 66.02%\n",
      "Epoch: 069 - Training loss: 0.6374 - Validation accuracy: 66.02%\n",
      "Epoch: 070 - Training loss: 0.6374 - Validation accuracy: 66.02%\n",
      "Epoch: 071 - Training loss: 0.6374 - Validation accuracy: 66.02%\n",
      "Epoch: 072 - Training loss: 0.6374 - Validation accuracy: 66.02%\n",
      "Epoch: 073 - Training loss: 0.6374 - Validation accuracy: 66.02%\n",
      "Epoch: 074 - Training loss: 0.6374 - Validation accuracy: 66.02%\n",
      "Epoch: 075 - Training loss: 0.6374 - Validation accuracy: 66.02%\n",
      "Epoch: 076 - Training loss: 0.6373 - Validation accuracy: 66.02%\n",
      "Epoch: 077 - Training loss: 0.6373 - Validation accuracy: 66.02%\n",
      "Epoch: 078 - Training loss: 0.6373 - Validation accuracy: 66.02%\n",
      "Epoch: 079 - Training loss: 0.6373 - Validation accuracy: 66.02%\n",
      "Epoch: 080 - Training loss: 0.6373 - Validation accuracy: 66.02%\n",
      "Epoch: 081 - Training loss: 0.6372 - Validation accuracy: 66.02%\n",
      "Epoch: 082 - Training loss: 0.6372 - Validation accuracy: 66.02%\n",
      "Epoch: 083 - Training loss: 0.6372 - Validation accuracy: 66.02%\n",
      "Epoch: 084 - Training loss: 0.6372 - Validation accuracy: 66.02%\n",
      "Epoch: 085 - Training loss: 0.6371 - Validation accuracy: 66.02%\n",
      "Epoch: 086 - Training loss: 0.6371 - Validation accuracy: 66.02%\n",
      "Epoch: 087 - Training loss: 0.6371 - Validation accuracy: 66.02%\n",
      "Epoch: 088 - Training loss: 0.6371 - Validation accuracy: 66.02%\n",
      "Epoch: 089 - Training loss: 0.6370 - Validation accuracy: 66.02%\n",
      "Epoch: 090 - Training loss: 0.6370 - Validation accuracy: 66.02%\n",
      "Epoch: 091 - Training loss: 0.6370 - Validation accuracy: 66.02%\n",
      "Epoch: 092 - Training loss: 0.6369 - Validation accuracy: 66.02%\n",
      "Epoch: 093 - Training loss: 0.6369 - Validation accuracy: 66.02%\n",
      "Epoch: 094 - Training loss: 0.6368 - Validation accuracy: 66.02%\n",
      "Epoch: 095 - Training loss: 0.6368 - Validation accuracy: 66.02%\n",
      "Epoch: 096 - Training loss: 0.6368 - Validation accuracy: 66.02%\n",
      "Epoch: 097 - Training loss: 0.6367 - Validation accuracy: 66.02%\n",
      "Epoch: 098 - Training loss: 0.6366 - Validation accuracy: 66.02%\n",
      "Epoch: 099 - Training loss: 0.6366 - Validation accuracy: 66.02%\n",
      "Epoch: 100 - Training loss: 0.6365 - Validation accuracy: 66.02%\n",
      "Epoch: 101 - Training loss: 0.6364 - Validation accuracy: 66.02%\n",
      "Epoch: 102 - Training loss: 0.6364 - Validation accuracy: 66.02%\n",
      "Epoch: 103 - Training loss: 0.6364 - Validation accuracy: 66.02%\n",
      "Epoch: 104 - Training loss: 0.6363 - Validation accuracy: 66.02%\n",
      "Epoch: 105 - Training loss: 0.6362 - Validation accuracy: 66.02%\n",
      "Epoch: 106 - Training loss: 0.6361 - Validation accuracy: 66.02%\n",
      "Epoch: 107 - Training loss: 0.6360 - Validation accuracy: 66.02%\n",
      "Epoch: 108 - Training loss: 0.6359 - Validation accuracy: 66.02%\n",
      "Epoch: 109 - Training loss: 0.6357 - Validation accuracy: 66.02%\n",
      "Epoch: 110 - Training loss: 0.6356 - Validation accuracy: 66.02%\n",
      "Epoch: 111 - Training loss: 0.6354 - Validation accuracy: 66.02%\n",
      "Epoch: 112 - Training loss: 0.6353 - Validation accuracy: 66.02%\n",
      "Epoch: 113 - Training loss: 0.6351 - Validation accuracy: 66.02%\n",
      "Epoch: 114 - Training loss: 0.6349 - Validation accuracy: 66.02%\n",
      "Epoch: 115 - Training loss: 0.6347 - Validation accuracy: 66.02%\n",
      "Epoch: 116 - Training loss: 0.6345 - Validation accuracy: 66.02%\n",
      "Epoch: 117 - Training loss: 0.6342 - Validation accuracy: 66.02%\n",
      "Epoch: 118 - Training loss: 0.6339 - Validation accuracy: 66.02%\n",
      "Epoch: 119 - Training loss: 0.6336 - Validation accuracy: 66.02%\n",
      "Epoch: 120 - Training loss: 0.6332 - Validation accuracy: 66.02%\n",
      "Epoch: 121 - Training loss: 0.6328 - Validation accuracy: 66.02%\n",
      "Epoch: 122 - Training loss: 0.6324 - Validation accuracy: 66.02%\n",
      "Epoch: 123 - Training loss: 0.6318 - Validation accuracy: 66.02%\n",
      "Epoch: 124 - Training loss: 0.6313 - Validation accuracy: 66.02%\n",
      "Epoch: 125 - Training loss: 0.6305 - Validation accuracy: 66.02%\n",
      "Epoch: 126 - Training loss: 0.6299 - Validation accuracy: 66.02%\n",
      "Epoch: 127 - Training loss: 0.6294 - Validation accuracy: 66.02%\n",
      "Epoch: 128 - Training loss: 0.6286 - Validation accuracy: 66.02%\n",
      "Epoch: 129 - Training loss: 0.6269 - Validation accuracy: 66.02%\n",
      "Epoch: 130 - Training loss: 0.6272 - Validation accuracy: 66.02%\n",
      "Epoch: 131 - Training loss: 0.6245 - Validation accuracy: 66.02%\n",
      "Epoch: 132 - Training loss: 0.6237 - Validation accuracy: 66.02%\n",
      "Epoch: 133 - Training loss: 0.6219 - Validation accuracy: 66.02%\n",
      "Epoch: 134 - Training loss: 0.6195 - Validation accuracy: 66.02%\n",
      "Epoch: 135 - Training loss: 0.6175 - Validation accuracy: 66.02%\n",
      "Epoch: 136 - Training loss: 0.6148 - Validation accuracy: 66.02%\n",
      "Epoch: 137 - Training loss: 0.6111 - Validation accuracy: 66.02%\n",
      "Epoch: 138 - Training loss: 0.6075 - Validation accuracy: 66.02%\n",
      "Epoch: 139 - Training loss: 0.6029 - Validation accuracy: 66.02%\n",
      "Epoch: 140 - Training loss: 0.5977 - Validation accuracy: 66.05%\n",
      "Epoch: 141 - Training loss: 0.5902 - Validation accuracy: 66.09%\n",
      "Epoch: 142 - Training loss: 0.5802 - Validation accuracy: 66.38%\n",
      "Epoch: 143 - Training loss: 0.5604 - Validation accuracy: 66.62%\n",
      "Epoch: 144 - Training loss: 0.5700 - Validation accuracy: 60.79%\n",
      "Epoch: 145 - Training loss: 0.6899 - Validation accuracy: 75.78%\n",
      "Epoch: 146 - Training loss: 0.5661 - Validation accuracy: 67.30%\n",
      "Epoch: 147 - Training loss: 0.5612 - Validation accuracy: 67.73%\n",
      "Epoch: 148 - Training loss: 0.5581 - Validation accuracy: 80.20%\n",
      "Epoch: 149 - Training loss: 0.5194 - Validation accuracy: 83.74%\n",
      "Epoch: 150 - Training loss: 0.4980 - Validation accuracy: 74.54%\n",
      "Epoch: 151 - Training loss: 0.5027 - Validation accuracy: 82.43%\n",
      "Epoch: 152 - Training loss: 0.4700 - Validation accuracy: 83.34%\n",
      "Epoch: 153 - Training loss: 0.4360 - Validation accuracy: 77.09%\n",
      "Epoch: 154 - Training loss: 0.4317 - Validation accuracy: 84.52%\n",
      "Epoch: 155 - Training loss: 0.4146 - Validation accuracy: 86.20%\n",
      "Epoch: 156 - Training loss: 0.3958 - Validation accuracy: 80.93%\n",
      "Epoch: 157 - Training loss: 0.3861 - Validation accuracy: 87.04%\n",
      "Epoch: 158 - Training loss: 0.3656 - Validation accuracy: 86.13%\n",
      "Epoch: 159 - Training loss: 0.3559 - Validation accuracy: 87.88%\n",
      "Epoch: 160 - Training loss: 0.3401 - Validation accuracy: 87.56%\n",
      "Epoch: 161 - Training loss: 0.3306 - Validation accuracy: 88.27%\n",
      "Epoch: 162 - Training loss: 0.3186 - Validation accuracy: 88.45%\n",
      "Epoch: 163 - Training loss: 0.3068 - Validation accuracy: 88.46%\n",
      "Epoch: 164 - Training loss: 0.2976 - Validation accuracy: 90.01%\n",
      "Epoch: 165 - Training loss: 0.2869 - Validation accuracy: 89.73%\n",
      "Epoch: 166 - Training loss: 0.2807 - Validation accuracy: 90.45%\n",
      "Epoch: 167 - Training loss: 0.2696 - Validation accuracy: 89.96%\n",
      "Epoch: 168 - Training loss: 0.2637 - Validation accuracy: 91.14%\n",
      "Epoch: 169 - Training loss: 0.2543 - Validation accuracy: 91.04%\n",
      "Epoch: 170 - Training loss: 0.2496 - Validation accuracy: 91.44%\n",
      "Epoch: 171 - Training loss: 0.2407 - Validation accuracy: 91.54%\n",
      "Epoch: 172 - Training loss: 0.2351 - Validation accuracy: 92.17%\n",
      "Epoch: 173 - Training loss: 0.2285 - Validation accuracy: 92.57%\n",
      "Epoch: 174 - Training loss: 0.2224 - Validation accuracy: 92.45%\n",
      "Epoch: 175 - Training loss: 0.2170 - Validation accuracy: 93.08%\n",
      "Epoch: 176 - Training loss: 0.2105 - Validation accuracy: 93.12%\n",
      "Epoch: 177 - Training loss: 0.2066 - Validation accuracy: 93.59%\n",
      "Epoch: 178 - Training loss: 0.2002 - Validation accuracy: 93.43%\n",
      "Epoch: 179 - Training loss: 0.1962 - Validation accuracy: 94.27%\n",
      "Epoch: 180 - Training loss: 0.1914 - Validation accuracy: 94.51%\n",
      "Epoch: 181 - Training loss: 0.1871 - Validation accuracy: 93.80%\n",
      "Epoch: 182 - Training loss: 0.1833 - Validation accuracy: 94.35%\n",
      "Epoch: 183 - Training loss: 0.1789 - Validation accuracy: 94.84%\n",
      "Epoch: 184 - Training loss: 0.1761 - Validation accuracy: 94.31%\n",
      "Epoch: 185 - Training loss: 0.1721 - Validation accuracy: 94.33%\n",
      "Epoch: 186 - Training loss: 0.1690 - Validation accuracy: 95.07%\n",
      "Epoch: 187 - Training loss: 0.1663 - Validation accuracy: 94.80%\n",
      "Epoch: 188 - Training loss: 0.1631 - Validation accuracy: 94.47%\n",
      "Epoch: 189 - Training loss: 0.1608 - Validation accuracy: 95.19%\n",
      "Epoch: 190 - Training loss: 0.1581 - Validation accuracy: 95.02%\n",
      "Epoch: 191 - Training loss: 0.1557 - Validation accuracy: 94.73%\n",
      "Epoch: 192 - Training loss: 0.1538 - Validation accuracy: 95.16%\n",
      "Epoch: 193 - Training loss: 0.1516 - Validation accuracy: 95.21%\n",
      "Epoch: 194 - Training loss: 0.1497 - Validation accuracy: 94.90%\n",
      "Epoch: 195 - Training loss: 0.1482 - Validation accuracy: 95.30%\n",
      "Epoch: 196 - Training loss: 0.1464 - Validation accuracy: 95.30%\n",
      "Epoch: 197 - Training loss: 0.1449 - Validation accuracy: 95.06%\n",
      "Epoch: 198 - Training loss: 0.1436 - Validation accuracy: 95.30%\n",
      "Epoch: 199 - Training loss: 0.1422 - Validation accuracy: 95.40%\n",
      "Epoch: 200 - Training loss: 0.1410 - Validation accuracy: 95.19%\n",
      "Epoch: 201 - Training loss: 0.1400 - Validation accuracy: 95.42%\n",
      "Epoch: 202 - Training loss: 0.1389 - Validation accuracy: 95.48%\n",
      "Epoch: 203 - Training loss: 0.1380 - Validation accuracy: 95.37%\n",
      "Epoch: 204 - Training loss: 0.1371 - Validation accuracy: 95.51%\n",
      "Epoch: 205 - Training loss: 0.1362 - Validation accuracy: 95.54%\n",
      "Epoch: 206 - Training loss: 0.1355 - Validation accuracy: 95.45%\n",
      "Epoch: 207 - Training loss: 0.1348 - Validation accuracy: 95.53%\n",
      "Epoch: 208 - Training loss: 0.1341 - Validation accuracy: 95.50%\n",
      "Epoch: 209 - Training loss: 0.1334 - Validation accuracy: 95.52%\n",
      "Epoch: 210 - Training loss: 0.1328 - Validation accuracy: 95.59%\n",
      "Epoch: 211 - Training loss: 0.1322 - Validation accuracy: 95.56%\n",
      "Epoch: 212 - Training loss: 0.1316 - Validation accuracy: 95.60%\n",
      "Epoch: 213 - Training loss: 0.1311 - Validation accuracy: 95.65%\n",
      "Epoch: 214 - Training loss: 0.1306 - Validation accuracy: 95.63%\n",
      "Epoch: 215 - Training loss: 0.1300 - Validation accuracy: 95.71%\n",
      "Epoch: 216 - Training loss: 0.1295 - Validation accuracy: 95.72%\n",
      "Epoch: 217 - Training loss: 0.1290 - Validation accuracy: 95.71%\n",
      "Epoch: 218 - Training loss: 0.1285 - Validation accuracy: 95.70%\n",
      "Epoch: 219 - Training loss: 0.1280 - Validation accuracy: 95.71%\n",
      "Epoch: 220 - Training loss: 0.1275 - Validation accuracy: 95.76%\n",
      "Epoch: 221 - Training loss: 0.1271 - Validation accuracy: 95.72%\n",
      "Epoch: 222 - Training loss: 0.1266 - Validation accuracy: 95.76%\n",
      "Epoch: 223 - Training loss: 0.1262 - Validation accuracy: 95.71%\n",
      "Epoch: 224 - Training loss: 0.1257 - Validation accuracy: 95.83%\n",
      "Epoch: 225 - Training loss: 0.1253 - Validation accuracy: 95.79%\n",
      "Epoch: 226 - Training loss: 0.1249 - Validation accuracy: 95.85%\n",
      "Epoch: 227 - Training loss: 0.1245 - Validation accuracy: 95.84%\n",
      "Epoch: 228 - Training loss: 0.1241 - Validation accuracy: 95.87%\n",
      "Epoch: 229 - Training loss: 0.1237 - Validation accuracy: 95.88%\n",
      "Epoch: 230 - Training loss: 0.1234 - Validation accuracy: 95.88%\n",
      "Epoch: 231 - Training loss: 0.1230 - Validation accuracy: 95.92%\n",
      "Epoch: 232 - Training loss: 0.1227 - Validation accuracy: 95.91%\n",
      "Epoch: 233 - Training loss: 0.1224 - Validation accuracy: 95.89%\n",
      "Epoch: 234 - Training loss: 0.1221 - Validation accuracy: 95.91%\n",
      "Epoch: 235 - Training loss: 0.1218 - Validation accuracy: 95.93%\n",
      "Epoch: 236 - Training loss: 0.1216 - Validation accuracy: 95.92%\n",
      "Epoch: 237 - Training loss: 0.1214 - Validation accuracy: 95.89%\n",
      "Epoch: 238 - Training loss: 0.1214 - Validation accuracy: 95.86%\n",
      "Epoch: 239 - Training loss: 0.1216 - Validation accuracy: 95.77%\n",
      "Epoch: 240 - Training loss: 0.1224 - Validation accuracy: 95.44%\n",
      "Epoch: 241 - Training loss: 0.1239 - Validation accuracy: 95.26%\n",
      "Epoch: 242 - Training loss: 0.1254 - Validation accuracy: 95.48%\n",
      "Epoch: 243 - Training loss: 0.1236 - Validation accuracy: 95.87%\n",
      "Epoch: 244 - Training loss: 0.1203 - Validation accuracy: 95.91%\n",
      "Epoch: 245 - Training loss: 0.1203 - Validation accuracy: 95.66%\n",
      "Epoch: 246 - Training loss: 0.1221 - Validation accuracy: 95.88%\n",
      "Epoch: 247 - Training loss: 0.1206 - Validation accuracy: 96.05%\n",
      "Epoch: 248 - Training loss: 0.1195 - Validation accuracy: 95.85%\n",
      "Epoch: 249 - Training loss: 0.1209 - Validation accuracy: 95.89%\n",
      "Epoch: 250 - Training loss: 0.1202 - Validation accuracy: 95.95%\n",
      "Epoch: 251 - Training loss: 0.1191 - Validation accuracy: 95.85%\n",
      "Epoch: 252 - Training loss: 0.1201 - Validation accuracy: 95.92%\n",
      "Epoch: 253 - Training loss: 0.1195 - Validation accuracy: 96.03%\n",
      "Epoch: 254 - Training loss: 0.1187 - Validation accuracy: 95.86%\n",
      "Epoch: 255 - Training loss: 0.1195 - Validation accuracy: 95.92%\n",
      "Epoch: 256 - Training loss: 0.1189 - Validation accuracy: 95.96%\n",
      "Epoch: 257 - Training loss: 0.1183 - Validation accuracy: 95.93%\n",
      "Epoch: 258 - Training loss: 0.1189 - Validation accuracy: 95.98%\n",
      "Epoch: 259 - Training loss: 0.1185 - Validation accuracy: 95.97%\n",
      "Epoch: 260 - Training loss: 0.1179 - Validation accuracy: 95.97%\n",
      "Epoch: 261 - Training loss: 0.1183 - Validation accuracy: 95.92%\n",
      "Epoch: 262 - Training loss: 0.1181 - Validation accuracy: 95.99%\n",
      "Epoch: 263 - Training loss: 0.1176 - Validation accuracy: 95.99%\n",
      "Epoch: 264 - Training loss: 0.1178 - Validation accuracy: 95.97%\n",
      "Epoch: 265 - Training loss: 0.1178 - Validation accuracy: 96.04%\n",
      "Epoch: 266 - Training loss: 0.1173 - Validation accuracy: 96.02%\n",
      "Epoch: 267 - Training loss: 0.1172 - Validation accuracy: 95.95%\n",
      "Epoch: 268 - Training loss: 0.1173 - Validation accuracy: 96.00%\n",
      "Epoch: 269 - Training loss: 0.1170 - Validation accuracy: 96.02%\n",
      "Epoch: 270 - Training loss: 0.1168 - Validation accuracy: 95.98%\n",
      "Epoch: 271 - Training loss: 0.1169 - Validation accuracy: 96.01%\n",
      "Epoch: 272 - Training loss: 0.1168 - Validation accuracy: 95.99%\n",
      "Epoch: 273 - Training loss: 0.1164 - Validation accuracy: 96.03%\n",
      "Epoch: 274 - Training loss: 0.1164 - Validation accuracy: 96.02%\n",
      "Epoch: 275 - Training loss: 0.1164 - Validation accuracy: 96.02%\n",
      "Epoch: 276 - Training loss: 0.1162 - Validation accuracy: 96.02%\n",
      "Epoch: 277 - Training loss: 0.1160 - Validation accuracy: 96.05%\n",
      "Epoch: 278 - Training loss: 0.1159 - Validation accuracy: 96.02%\n",
      "Epoch: 279 - Training loss: 0.1159 - Validation accuracy: 96.06%\n",
      "Epoch: 280 - Training loss: 0.1157 - Validation accuracy: 96.01%\n",
      "Epoch: 281 - Training loss: 0.1155 - Validation accuracy: 96.05%\n",
      "Epoch: 282 - Training loss: 0.1154 - Validation accuracy: 96.07%\n",
      "Epoch: 283 - Training loss: 0.1154 - Validation accuracy: 96.04%\n",
      "Epoch: 284 - Training loss: 0.1153 - Validation accuracy: 96.05%\n",
      "Epoch: 285 - Training loss: 0.1151 - Validation accuracy: 96.03%\n",
      "Epoch: 286 - Training loss: 0.1149 - Validation accuracy: 96.07%\n",
      "Epoch: 287 - Training loss: 0.1149 - Validation accuracy: 96.07%\n",
      "Epoch: 288 - Training loss: 0.1148 - Validation accuracy: 96.08%\n",
      "Epoch: 289 - Training loss: 0.1146 - Validation accuracy: 96.06%\n",
      "Epoch: 290 - Training loss: 0.1145 - Validation accuracy: 96.04%\n",
      "Epoch: 291 - Training loss: 0.1143 - Validation accuracy: 96.05%\n",
      "Epoch: 292 - Training loss: 0.1142 - Validation accuracy: 96.05%\n",
      "Epoch: 293 - Training loss: 0.1141 - Validation accuracy: 96.05%\n",
      "Epoch: 294 - Training loss: 0.1141 - Validation accuracy: 96.05%\n",
      "Epoch: 295 - Training loss: 0.1140 - Validation accuracy: 96.06%\n",
      "Epoch: 296 - Training loss: 0.1139 - Validation accuracy: 96.06%\n",
      "Epoch: 297 - Training loss: 0.1138 - Validation accuracy: 96.07%\n",
      "Epoch: 298 - Training loss: 0.1137 - Validation accuracy: 96.09%\n",
      "Epoch: 299 - Training loss: 0.1136 - Validation accuracy: 96.10%\n",
      "Epoch: 300 - Training loss: 0.1136 - Validation accuracy: 96.14%\n",
      "Epoch: 301 - Training loss: 0.1136 - Validation accuracy: 96.02%\n",
      "Epoch: 302 - Training loss: 0.1137 - Validation accuracy: 96.05%\n",
      "Epoch: 303 - Training loss: 0.1140 - Validation accuracy: 95.89%\n",
      "Epoch: 304 - Training loss: 0.1148 - Validation accuracy: 95.67%\n",
      "Epoch: 305 - Training loss: 0.1161 - Validation accuracy: 95.47%\n",
      "Epoch: 306 - Training loss: 0.1176 - Validation accuracy: 95.42%\n",
      "Epoch: 307 - Training loss: 0.1174 - Validation accuracy: 95.83%\n",
      "Epoch: 308 - Training loss: 0.1147 - Validation accuracy: 96.11%\n",
      "Epoch: 309 - Training loss: 0.1127 - Validation accuracy: 95.94%\n",
      "Epoch: 310 - Training loss: 0.1140 - Validation accuracy: 95.79%\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 31\u001b[0m\n\u001b[1;32m     28\u001b[0m       \u001b[39mreturn\u001b[39;00m test_acc, test_out, test_pred\n\u001b[1;32m     30\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39m401\u001b[39m):\n\u001b[0;32m---> 31\u001b[0m     train_loss \u001b[39m=\u001b[39m train()\n\u001b[1;32m     32\u001b[0m     val_loss, _, _ \u001b[39m=\u001b[39m test(data\u001b[39m.\u001b[39mval_mask)\n\u001b[1;32m     33\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mEpoch: \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m:\u001b[39;00m\u001b[39m03d\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m - Training loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m:\u001b[39;00m\u001b[39m.4f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m - \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     34\u001b[0m           \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mValidation accuracy: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m \u001b[39m\u001b[39m*\u001b[39m\u001b[39m \u001b[39m\u001b[39m100\u001b[39m\u001b[39m:\u001b[39;00m\u001b[39m.2f\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m'\u001b[39m)\n",
      "Cell \u001b[0;32mIn[55], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     11\u001b[0m \u001b[39m# We now give as input also the graph connectivity\u001b[39;00m\n\u001b[1;32m     12\u001b[0m \u001b[39m#out = model(data.x, gso_index, gso_weight)\u001b[39;00m\n\u001b[0;32m---> 13\u001b[0m out \u001b[39m=\u001b[39m model(data\u001b[39m.\u001b[39;49mx, data\u001b[39m.\u001b[39;49medge_index, data\u001b[39m.\u001b[39;49medge_attr)\n\u001b[1;32m     14\u001b[0m \u001b[39m#print(len(out[data.train_mask]),len(data.y[data.train_mask]))\u001b[39;00m\n\u001b[1;32m     15\u001b[0m loss \u001b[39m=\u001b[39m criterion(out[data\u001b[39m.\u001b[39mtrain_mask], data\u001b[39m.\u001b[39my[data\u001b[39m.\u001b[39mtrain_mask])\n",
      "File \u001b[0;32m~/anaconda3/envs/GDL/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[53], line 33\u001b[0m, in \u001b[0;36mGNNModel.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x, edge_index, edge_attr\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m     30\u001b[0m     \u001b[39m# Message-passing: transform node features based on neighbors\u001b[39;00m\n\u001b[1;32m     31\u001b[0m     \u001b[39mfor\u001b[39;00m mpnn \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmpnns:\n\u001b[1;32m     32\u001b[0m         \u001b[39m#x = mpnn(x, edge_index, edge_weight)\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m         x \u001b[39m=\u001b[39m mpnn(x, edge_index, edge_attr\u001b[39m=\u001b[39;49medge_attr)\n\u001b[1;32m     34\u001b[0m     \u001b[39m# Decoder: post-process extracted features\u001b[39;00m\n\u001b[1;32m     35\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_out(x)\n",
      "File \u001b[0;32m~/anaconda3/envs/GDL/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[52], line 42\u001b[0m, in \u001b[0;36mMPNN.forward\u001b[0;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[1;32m     38\u001b[0m m_ji \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlin_message(x)  \u001b[39m# we can project here with isotropic GNNs\u001b[39;00m\n\u001b[1;32m     39\u001b[0m \u001b[39m#m_ji = x  # I decided since we only have one feature, it doesnt make sense to apply a linear to dim 16\u001b[39;00m\n\u001b[1;32m     40\u001b[0m \u001b[39m# 2. m_𝑖 = add(ã_ji ⋅ m_j→𝑖)_j∈𝑁(i)\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \u001b[39m#print('mji', m_ji.size())\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m m_i \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, m\u001b[39m=\u001b[39;49mm_ji, edge_attr\u001b[39m=\u001b[39;49medge_attr)\n\u001b[1;32m     43\u001b[0m \u001b[39m# 3. h_𝑖 = tanh(x_i𝚯_2 + m_i + 𝐛)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[39m#print('mi', m_i.size())\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39m#h_i = torch.tanh(self.lin_update(x) + m_i)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m a \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat([x, m_i], dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/GDL/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:467\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    466\u001b[0m         msg_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[0;32m--> 467\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmessage(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mmsg_kwargs)\n\u001b[1;32m    468\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_message_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    469\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (msg_kwargs, ), out)\n",
      "Cell \u001b[0;32mIn[52], line 65\u001b[0m, in \u001b[0;36mMPNN.message\u001b[0;34m(self, m_j, edge_attr)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmessage\u001b[39m(\u001b[39mself\u001b[39m, m_j, edge_attr):\n\u001b[1;32m     57\u001b[0m     \u001b[39m# x_j has shape [E, in_channels]\u001b[39;00m\n\u001b[1;32m     58\u001b[0m     \u001b[39m# edge_attr has shape [E, edge_dim]\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[39m#return edge_attr.reshape(-1, 1) * m_j\u001b[39;00m\n\u001b[1;32m     64\u001b[0m     \u001b[39m#return edge_attr.view(-1, 1) * m_j\u001b[39;00m\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49mcat([m_j, edge_attr], dim\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import Javascript  # Restrict height of output cell.\n",
    "display(Javascript('''google.colab.output.setIframeHeight(0, true, {maxHeight: 100})'''))\n",
    "\n",
    "model = GNNModel(HIDDEN_SIZE, NUM_LAYERS)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "def train():\n",
    "      model.train()\n",
    "      optimizer.zero_grad()\n",
    "      # We now give as input also the graph connectivity\n",
    "      #out = model(data.x, gso_index, gso_weight)\n",
    "      out = model(data.x, data.edge_index, data.edge_attr)\n",
    "      #print(len(out[data.train_mask]),len(data.y[data.train_mask]))\n",
    "      loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      return loss\n",
    "\n",
    "def test(mask):\n",
    "      model.eval()\n",
    "      out = model(data.x, data.edge_index, data.edge_attr)\n",
    "      pred = out.argmax(dim=1)\n",
    "      test_correct = pred[mask] == data.y[mask]\n",
    "      test_acc = int(test_correct.sum()) / int(mask.sum())\n",
    "      test_out = out[mask]\n",
    "      test_pred = pred[mask]\n",
    "      return test_acc, test_out, test_pred\n",
    "\n",
    "for epoch in range(1, 401):\n",
    "    train_loss = train()\n",
    "    val_loss, _, _ = test(data.val_mask)\n",
    "    print(f'Epoch: {epoch:03d} - Training loss: {train_loss:.4f} - '\n",
    "          f'Validation accuracy: {val_loss * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 95.89%\n",
      "tensor([0, 0, 0,  ..., 0, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_out, test_pred  = test(data.test_mask)\n",
    "print(f'Test Accuracy: {test_acc * 100:.2f}%')\n",
    "print(test_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(data.x, data.edge_index, data.edge_attr)\n",
    "#visualize(out, color=data.y)\n",
    "#visualize(out[data.test_mask], color=data.y[data.test_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00422117 0.47074187 0.00958515 ... 0.00688851 0.8157754  0.99851555]\n",
      "Precision: 0.91\n",
      "Recall: 0.98\n",
      "F1-score: 0.94\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_fscore_support\n",
    "import torch.nn.functional as F\n",
    "\n",
    "y_true = data.y[data.test_mask]\n",
    "y_pred = softmax_x = F.softmax(test_out, dim=1)\n",
    "y_pred = y_pred[:, 1].detach().numpy()\n",
    "print(y_pred)\n",
    "\n",
    "# Calculate precision, recall, and F1-score\n",
    "precision, recall, f1_score, _ = precision_recall_fscore_support(y_true, test_pred, average='binary')\n",
    "\n",
    "print(\"Precision: {:.2f}\".format(precision))\n",
    "print(\"Recall: {:.2f}\".format(recall))\n",
    "print(\"F1-score: {:.2f}\".format(f1_score))\n",
    "\n",
    "# Generate ROC curve\n",
    "fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (AUC = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic (ROC) curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11109\n",
      "11109\n",
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False, False, False, False, False, False, False, False, False, False,\n",
       "        False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data.y[data.test_mask]))\n",
    "print(len(y_pred))\n",
    "orig_test_y = data.y[data.test_mask]\n",
    "b = test_pred == orig_test_y\n",
    "c = b[orig_test_y == 1]\n",
    "print(np.sum(c.numpy()/len(c)))\n",
    "\n",
    "c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
